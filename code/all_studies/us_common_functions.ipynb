{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09a97b3",
   "metadata": {},
   "source": [
    "# Common Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b106f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "import pprint\n",
    "import copy\n",
    "import json \n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mode\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from IPython.display import IFrame, display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, plot_roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "# from keras.utils import to_categorical\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tf_k\n",
    "import tensorflow_addons as tf_a\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate, ConvLSTM1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8cd2de",
   "metadata": {},
   "source": [
    "# Common Variables\n",
    "## Remember - Don't put any variable that may change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c90fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    'Accuracy': [],\n",
    "    'AUC': [],\n",
    "    'F1': [],\n",
    "    'Recall': [],\n",
    "    'Precision': [],\n",
    "    'Specificity': [],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': [],\n",
    "    'Arousal_Signal': [],\n",
    "    \n",
    "    'Train_Study': [],\n",
    "    'Test_Study': [],\n",
    "})\n",
    "\n",
    "for metric in all_metrics.keys():\n",
    "    metrics_df['Train_' + metric] = []\n",
    "    metrics_df['Test_' + metric] = []\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "model_features = [\n",
    "    'Age', 'Gender',     \n",
    "    'NASA_Physical', 'NASA_Effort', 'NASA_Frustration', 'NASA_Temporal', 'NASA_Performance',          \n",
    "    'PP_Mean', 'PP_SD',     \n",
    "    'HR_Mean', 'HR_SD',\n",
    "    'BR_Mean', 'BR_SD'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "model_train_method = 'kfold' ### ['best_accurate', 'kfold', 'bootstrap']\n",
    "\n",
    "# if model_train_method=='best_accurate':\n",
    "#     _range=1\n",
    "#     random_selection=False\n",
    "    \n",
    "# elif model_train_method=='bootstrap':\n",
    "#     _range=30\n",
    "#     random_selection=True\n",
    "    \n",
    "# elif model_train_method=='kfold':\n",
    "#     kf = KFold(n_splits=k_fold_n_splits)\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "prediction_threshold = 0.5\n",
    "\n",
    "\n",
    "non_arousal_threshold_ecdf = 0.33\n",
    "arousal_threshold_ecdf = 0.67\n",
    "    \n",
    "    \n",
    "dnn_model_name = None\n",
    "\n",
    "running_study = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b3d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1 = 'sim1'\n",
    "sim2 = 'sim2'\n",
    "tt1 = 'tt1'\n",
    "office_tasks = 'office_tasks'\n",
    "deadline_study = 'deadline_study'\n",
    "all_studies = 'all_studies'\n",
    "\n",
    "\n",
    "data_dir = '../../data/'\n",
    "fig_dir = '../../figure/'\n",
    "metrics_dir = 'metrics'\n",
    "models_dir = 'models'\n",
    "\n",
    "\n",
    "def add_path(path1, path2):\n",
    "    return path1+path2+'/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sim1_data_dir = add_path(data_dir, sim1)\n",
    "# sim1_fig_dir = add_path(fig_dir, sim1)\n",
    "\n",
    "sim2_data_dir = add_path(data_dir, sim2)\n",
    "# sim2_fig_dir = add_path(fig_dir, sim2)\n",
    "\n",
    "tt1_data_dir = add_path(data_dir, tt1)\n",
    "# tt1_fig_dir = add_path(fig_dir, tt1)\n",
    "\n",
    "office_tasks_data_dir = add_path(data_dir, office_tasks)\n",
    "# office_tasks_fig_dir = add_path(fig_dir, office_tasks)\n",
    "\n",
    "deadline_study_data_dir = add_path(data_dir, deadline_study)\n",
    "# deadline_study_fig_dir = add_path(fig_dir, deadline_study)\n",
    "\n",
    "all_studies_data_dir = add_path(data_dir, all_studies)\n",
    "all_studies_fig_dir = add_path(fig_dir, all_studies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1793173-ef79-4c2a-8c21-c2366291e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_ecdf_combinations = {\n",
    "    'sim1___sim2': ['sim1', 'sim2'],\n",
    "    'sim1___sim2___tt1': ['sim1', 'sim2', 'tt1'],\n",
    "    'sim1___sim2___office_tasks': ['sim1', 'sim2', 'office_tasks'],\n",
    "    'sim1___sim2___tt1___office_tasks': ['sim1', 'sim2', 'tt1', 'office_tasks'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dbd52e-0695-49d6-9155-663c55f0f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_combinations(studies):\n",
    "\n",
    "    study_combinations = {}\n",
    "\n",
    "    for i in range(1, len(studies)+1):\n",
    "        # print('\\nTotal Train Study: ' + str(i))\n",
    "        for study_subset in itertools.combinations(studies, i):\n",
    "            train_studies = list(study_subset)\n",
    "            test_studies = [study for study in studies if study not in train_studies]  \n",
    "            study_combination = '___'.join(study_subset)\n",
    "            study_combinations[study_combination] = {'Train': train_studies, 'Test': test_studies}\n",
    "            # print(train_studies, test_studies, study_combination)\n",
    "\n",
    "    # pprint.pprint(study_combinations)\n",
    "    \n",
    "\n",
    "    all_study_combinations = studies + list(study_ecdf_combinations.keys())\n",
    "    # print(all_study_combinations)\n",
    "    \n",
    "    return study_combinations, all_study_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388e2162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim1',\n",
       " 'sim2',\n",
       " 'tt1',\n",
       " 'office_tasks',\n",
       " 'deadline_study',\n",
       " 'sim1___sim2',\n",
       " 'sim1___sim2___tt1',\n",
       " 'sim1___sim2___office_tasks',\n",
       " 'sim1___sim2___tt1___office_tasks']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### studies = [sim1, sim2, tt1, office_tasks, deadline_study]\n",
    "studies = [sim1, sim2, tt1, office_tasks]\n",
    "\n",
    "study_combinations, all_study_combinations = get_study_combinations(studies+[deadline_study])\n",
    "all_study_combinations\n",
    "\n",
    "# Total Train Study: 1\n",
    "# ['sim1'] ['sim2', 'tt1', 'office_tasks'] sim1\n",
    "# ['sim2'] ['sim1', 'tt1', 'office_tasks'] sim2\n",
    "# ['tt1'] ['sim1', 'sim2', 'office_tasks'] tt1\n",
    "# ['office_tasks'] ['sim1', 'sim2', 'tt1'] office_tasks\n",
    "\n",
    "# Total Train Study: 2\n",
    "# ['sim1', 'sim2'] ['tt1', 'office_tasks'] sim1___sim2\n",
    "# ['sim1', 'tt1'] ['sim2', 'office_tasks'] sim1___tt1\n",
    "# ['sim1', 'office_tasks'] ['sim2', 'tt1'] sim1___office_tasks\n",
    "# ['sim2', 'tt1'] ['sim1', 'office_tasks'] sim2___tt1\n",
    "# ['sim2', 'office_tasks'] ['sim1', 'tt1'] sim2___office_tasks\n",
    "# ['tt1', 'office_tasks'] ['sim1', 'sim2'] tt1___office_tasks\n",
    "\n",
    "# Total Train Study: 3\n",
    "# ['sim1', 'sim2', 'tt1'] ['office_tasks'] sim1___sim2___tt1\n",
    "# ['sim1', 'sim2', 'office_tasks'] ['tt1'] sim1___sim2___office_tasks\n",
    "# ['sim1', 'tt1', 'office_tasks'] ['sim2'] sim1___tt1___office_tasks\n",
    "# ['sim2', 'tt1', 'office_tasks'] ['sim1'] sim2___tt1___office_tasks\n",
    "\n",
    "# Total Train Study: 4\n",
    "# ['sim1', 'sim2', 'tt1', 'office_tasks'] [] sim1___sim2___tt1___office_tasks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dict_keys(['sim1', \n",
    "#            'sim2', \n",
    "#            'tt1', \n",
    "#            'office_tasks', \n",
    "#            'sim1___sim2', \n",
    "#            'sim1___tt1', \n",
    "#            'sim1___office_tasks', \n",
    "#            'sim2___tt1', \n",
    "#            'sim2___office_tasks', \n",
    "#            'tt1___office_tasks', \n",
    "#            'sim1___sim2___tt1', \n",
    "#            'sim1___sim2___office_tasks', \n",
    "#            'sim1___tt1___office_tasks', \n",
    "#            'sim2___tt1___office_tasks', \n",
    "#            'sim1___sim2___tt1___office_tasks'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# {'office_tasks': {'Test': ['sim1', 'sim2', 'tt1'], 'Train': ['office_tasks']},\n",
    "#  'sim1': {'Test': ['sim2', 'tt1', 'office_tasks'], 'Train': ['sim1']},\n",
    "#  'sim1___office_tasks': {'Test': ['sim2', 'tt1'],\n",
    "#                          'Train': ['sim1', 'office_tasks']},\n",
    "#  'sim1___sim2': {'Test': ['tt1', 'office_tasks'], 'Train': ['sim1', 'sim2']},\n",
    "#  'sim1___sim2___office_tasks': {'Test': ['tt1'],\n",
    "#                                 'Train': ['sim1', 'sim2', 'office_tasks']},\n",
    "#  'sim1___sim2___tt1': {'Test': ['office_tasks'],\n",
    "#                        'Train': ['sim1', 'sim2', 'tt1']},\n",
    "#  'sim1___sim2___tt1___office_tasks': {'Test': [],\n",
    "#                                       'Train': ['sim1',\n",
    "#                                                 'sim2',\n",
    "#                                                 'tt1',\n",
    "#                                                 'office_tasks']},\n",
    "#  'sim1___tt1': {'Test': ['sim2', 'office_tasks'], 'Train': ['sim1', 'tt1']},\n",
    "#  'sim1___tt1___office_tasks': {'Test': ['sim2'],\n",
    "#                                'Train': ['sim1', 'tt1', 'office_tasks']},\n",
    "#  'sim2': {'Test': ['sim1', 'tt1', 'office_tasks'], 'Train': ['sim2']},\n",
    "#  'sim2___office_tasks': {'Test': ['sim1', 'tt1'],\n",
    "#                          'Train': ['sim2', 'office_tasks']},\n",
    "#  'sim2___tt1': {'Test': ['sim1', 'office_tasks'], 'Train': ['sim2', 'tt1']},\n",
    "#  'sim2___tt1___office_tasks': {'Test': ['sim1'],\n",
    "#                                'Train': ['sim2', 'tt1', 'office_tasks']},\n",
    "#  'tt1': {'Test': ['sim1', 'sim2', 'office_tasks'], 'Train': ['tt1']},\n",
    "#  'tt1___office_tasks': {'Test': ['sim1', 'sim2'],\n",
    "#                         'Train': ['tt1', 'office_tasks']}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6e271aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df):\n",
    "    df = df.copy().rename(columns={\n",
    "        \n",
    "         'Gender_Female': 'Gender', \n",
    "         'Effort': 'NASA_Effort',\n",
    "         'Frustration': 'NASA_Frustration', \n",
    "         'Performance': 'NASA_Performance',\n",
    "        \n",
    "        \n",
    "         'Mental_Demand': 'NASA_Mental',\n",
    "         'Physical_Demand': 'NASA_Physical',\n",
    "         'Temporal_Demand': 'NASA_Temporal', \n",
    "         'NASA_Total_Sum': 'NASA_Total',\n",
    "        \n",
    "         'Mental Demand': 'NASA_Mental',\n",
    "         'Physical Demand': 'NASA_Physical',\n",
    "         'Temporal Demand': 'NASA_Temporal', \n",
    "         'NASA Total Sum': 'NASA_Total',\n",
    "        \n",
    "        \n",
    "         'Perinasal_Mean': 'PP_Mean',\n",
    "         'Perinasal_SD': 'PP_SD',\n",
    "         'Perinasal_Median': 'PP_Median', \n",
    "         'Perinasal_SS': 'PP_SS',\n",
    "        \n",
    "        \n",
    "         'Hr_Mean': 'HR_Mean',\n",
    "         'Hr_SD': 'HR_SD',\n",
    "         'Hr_Median': 'HR_Median',\n",
    "         'Hr_SS': 'HR_SS',\n",
    "        \n",
    "         'Br_Mean': 'BR_Mean',\n",
    "         'Br_SD': 'BR_SD',\n",
    "         'Br_Median': 'BR_Median',\n",
    "         'Br_SS': 'BR_SS',\n",
    "        \n",
    "        \n",
    "         'Heart_Mean': 'HR_Mean',\n",
    "         'Heart_SD': 'HR_SD',\n",
    "         'Heart_Median': 'HR_Median',\n",
    "         'Heart_SS': 'HR_SS',\n",
    "        \n",
    "         'Breathing_Mean': 'BR_Mean',\n",
    "         'Breathing_SD': 'BR_SD',\n",
    "         'Breathing_Median': 'BR_Median',\n",
    "         'Breathing_SS': 'BR_SS'\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def change_ground_truth_labels(ground_truth_label):\n",
    "    if ground_truth_label=='relaxed':\n",
    "        new_ground_truth_label='non-arousal'\n",
    "    elif ground_truth_label=='stressed':\n",
    "        new_ground_truth_label='arousal'\n",
    "    else:\n",
    "        new_ground_truth_label=ground_truth_label\n",
    "        \n",
    "    return new_ground_truth_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_model(model_name='Random_Forest'):\n",
    "    \n",
    "    # Code for extension\n",
    "    if model_name=='Random_Forest':\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators = 200,\n",
    "            max_features = 'auto',\n",
    "            bootstrap = True)\n",
    "    elif model_name=='KNN':\n",
    "        model = KNeighborsClassifier(n_neighbors=3)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84b0f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_time():\n",
    "    return datetime.now().strftime('%m_%d_%Y_%H_%M_%S')\n",
    "\n",
    "\n",
    "metrics_point = 6\n",
    "\n",
    "def get_round(num, point=2): \n",
    "    return round(num, metrics_point) # point\n",
    "\n",
    "def get_rounded_str(num, point):\n",
    "    return str(get_round(num, metrics_point)) # point\n",
    "\n",
    "\n",
    "sum_of_squares = lambda x: sum(x**2)\n",
    "\n",
    "\n",
    "def concat_df(root_path, files, final_file_name):\n",
    "    final_df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        df = pd.read_csv(root_path+file)\n",
    "        final_df = pd.concat([final_df, df])\n",
    "        \n",
    "    final_df.to_csv(root_path+final_file_name)\n",
    "\n",
    "    \n",
    "def print_row_count(df, col_name):\n",
    "    df_count = df.groupby([col_name]).agg({col_name: 'count'})\n",
    "    print(df_count, '\\n')\n",
    "\n",
    "def print_percentage(df, col_name):\n",
    "    df_count = df.groupby([col_name]).agg({col_name: 'count'})\n",
    "    df_percentage = df_count.apply(lambda x: round(100 * x / float(x.sum()), 2))\n",
    "    print(df_percentage, '\\n')\n",
    "\n",
    "\n",
    "def get_study_subject_name(df):\n",
    "    df['Study_Subject'] = df.Study_Name + '_' + df.Subject.map(str)\n",
    "    return df\n",
    "\n",
    "def get_splitted_data(final_df, model_features, arousal_signal, predict_col, model_train_method, study_subjects_test=None):\n",
    "    \n",
    "    unique_study_subjs = final_df.Study_Subject.unique()\n",
    "    \n",
    "    df_count = final_df.groupby(['Arousal_Mode']).agg({'Arousal_Mode': 'count'})\n",
    "    df_count = df_count.apply(lambda x: 100 * x / float(x.sum()))\n",
    "    # print(df_count.head(2))\n",
    "\n",
    "    ########################################################################\n",
    "    '''\n",
    "    train_subj_end = 65\n",
    "\n",
    "    train_df = final_df[final_df.Subject < train_subj_end]\n",
    "    test_df = final_df[final_df.Subject >= train_subj_end]\n",
    "    \n",
    "    train_subjs = train_df.Subject.unique()\n",
    "    test_subjs = test_df.Subject.unique()\n",
    "    \n",
    "    print('\\n\\nTest Subjects -->\\n', test_subjs)\n",
    "    '''\n",
    "    ########################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################################################################\n",
    "    # '''\n",
    "    if model_train_method=='kfold':\n",
    "        test_study_subjs = study_subjects_test\n",
    "#     elif model_train_method=='best_accurate':\n",
    "#         test_subjs = get_test_subjs(arousal_signal)\n",
    "#     elif model_train_method=='bootstrap':\n",
    "#         test_subjs = random.sample(list(final_df.Subject.unique()), 7)\n",
    "        \n",
    "    \n",
    "    train_study_subjs = [subj for subj in unique_study_subjs if subj not in test_study_subjs]\n",
    "    \n",
    "    train_df = final_df[final_df.Study_Subject.isin(train_study_subjs)]\n",
    "    test_df = final_df[final_df.Study_Subject.isin(test_study_subjs)]\n",
    "    \n",
    "    # print('\\n\\nTest Subjects -->\\n', test_subjs)\n",
    "    # '''\n",
    "    ########################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('\\n\\nTotal Train Subjects: ' + str(len(train_subjs)) + '    Percentage: ' + str(round(100*len(train_subjs)/len(unique_subjs), 2)) + '%')\n",
    "#     print('Total Test Subjects: ' + str(len(test_subjs)) + '    Percentage: ' + str(round(100*len(test_subjs)/len(unique_subjs), 2)) + '%' + '\\n\\n')\n",
    "\n",
    "\n",
    "    train_df_count = train_df.groupby(['Arousal_Mode']).agg({'Arousal_Mode': 'count'})\n",
    "    train_df_count = train_df_count.apply(lambda x: 100 * x / float(x.sum()))\n",
    "#     print('Train Data Percentage -->')\n",
    "#     print(train_df_count)\n",
    "\n",
    "\n",
    "    test_df_count = test_df.groupby(['Arousal_Mode']).agg({'Arousal_Mode': 'count'})\n",
    "    test_df_count = test_df_count.apply(lambda x: 100 * x / float(x.sum()))\n",
    "#     print('\\nTest Data Percentage -->')\n",
    "#     print(test_df_count)\n",
    "\n",
    "\n",
    "#     print('\\n\\nTotal Train Rows: ' + str(len(train_df)) + '    Percentage: ' + str(round(100*len(train_df)/len(final_df), 2)) + '%')\n",
    "#     print('Total Test Rows: ' + str(len(test_df)) + '    Percentage: ' + str(round(100*len(test_df)/len(final_df), 2)) + '%' + '\\n\\n')\n",
    "\n",
    "    \n",
    "    X_train = train_df[model_features]\n",
    "    y_train = train_df[[predict_col]]\n",
    "\n",
    "    X_test = test_df[model_features]\n",
    "    y_test = test_df[[predict_col]]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ef4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(arousal_signal, y_test, y_pred, do_normalize=True):\n",
    "    \n",
    "    #####################################################################################\n",
    "    reset_plt()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    #-------------------------------------------------------------#\n",
    "    # labels = ['normal', 'relaxed', 'stressed', 'unknown']\n",
    "    # labels = ['relaxed', 'normal', 'unknown', 'stressed']\n",
    "    # labels = ['relaxed', 'stressed']\n",
    "    labels = sorted(train_df.Arousal_Mode.unique())\n",
    "    #-------------------------------------------------------------#\n",
    "    \n",
    "    if do_normalize:\n",
    "        conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=labels, normalize='all'))\n",
    "        sns.heatmap(conf_mat*100, annot=True, annot_kws={'size': 24})\n",
    "        # plt.title('Confusion Matrix - ' + arousal_signal + ' %', fontsize=40)\n",
    "        # plot_name = arousal_signal.lower() + '_percentage'\n",
    "        \n",
    "    else:\n",
    "        conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=labels))\n",
    "        # annot = [str(val)+'%' for val in conf_mat]\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', annot_kws={'size': 24})\n",
    "        # plt.title('Confusion Matrix - ' + arousal_signal, fontsize=40)\n",
    "        # plot_name = arousal_signal.lower() \n",
    "\n",
    "    ax.collections[0].colorbar.ax.tick_params(labelsize=28)\n",
    "    \n",
    "    ax.set_title('%')\n",
    "    \n",
    "    ax.set_xticklabels(labels, fontsize=24)\n",
    "    ax.set_yticklabels(labels, fontsize=24)\n",
    "    \n",
    "    ax.set_xlabel('Predicted', fontsize=32)\n",
    "    ax.set_ylabel('Actual', fontsize=32)\n",
    "\n",
    "    plt.savefig(figure_path + plot_name + '_confusion_matrix.png')\n",
    "    plt.savefig(figure_path + plot_name + '_confusion_matrix.pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "\n",
    "def get_all_confusion_matrices(arousal_signal, train_df, test_df, y_test, y_pred):\n",
    "    \n",
    "    get_confusion_matrix(arousal_signal, train_df, test_df, y_test, y_pred, do_normalize=True)\n",
    "    get_confusion_matrix(arousal_signal, train_df, test_df, y_test, y_pred, do_normalize=False)\n",
    "\n",
    "    #####################################################################################\n",
    "    # print('\\n\\nConfusion Matrix:')\n",
    "    # print(pd.DataFrame(confusion_matrix(y_test, y_pred, labels=labels)))\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    labels = sorted(train_df.Arousal_Mode.unique())\n",
    "    \n",
    "    reset_plt()\n",
    "    fig, axs = plt.subplots(3, figsize = (12, 36))\n",
    "    fig.suptitle(arousal_signal)\n",
    "\n",
    "    for i, treatment in enumerate(test_df.Treatment.unique()):\n",
    "        treatment_test_df = test_df.copy()[test_df.Treatment == treatment]\n",
    "        y_test_treatment = treatment_test_df.Arousal_Mode\n",
    "        y_pred_treatment = treatment_test_df.Prediction  ### Comment out the line --> test_df['Prediction'] = y_pred\n",
    "\n",
    "        conf_mat = pd.DataFrame(confusion_matrix(y_test_treatment, y_pred_treatment, labels = labels))\n",
    "        axis = axs[i]\n",
    "\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', annot_kws={'size': 24}, ax = axis)\n",
    "        axis.collections[0].colorbar.ax.tick_params(labelsize=32)\n",
    "        \n",
    "        axis.title.set_text(get_treatment_name(treatment))\n",
    "        axis.set_xticklabels(labels, fontsize=24)\n",
    "        axis.set_yticklabels(labels, fontsize=24)\n",
    "        axis.set_xlabel('Predicted', fontsize=24)\n",
    "        axis.set_ylabel('Actual', fontsize=24)\n",
    "\n",
    "#     plt.savefig(figure_path + arousal_signal.lower() + '_treatment_confusion_matrix.png')\n",
    "#     plt.savefig(figure_path + arousal_signal.lower() + '_treatment_confusion_matrix.pdf')\n",
    "    \n",
    "#     plt.show()\n",
    "    #####################################################################################\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_feature_importance(model, X_train):\n",
    "    \n",
    "    df_feature_importance = pd.DataFrame(model.feature_importances_, \n",
    "                                     index=X_train.columns, \n",
    "                                     columns=['feature importance']).sort_values('feature importance', ascending=False)\n",
    "    feature_imp = pd.Series(model.feature_importances_,\n",
    "                            index=X_train.columns).sort_values(ascending=False).round(2)\n",
    "\n",
    "    reset_plt()\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    \n",
    "    sns_plt = sns.barplot(x=feature_imp, y=feature_imp.index) \n",
    "    \n",
    "    # plt.title(arousal_signal + ' - Important Features', fontsize=36)\n",
    "    # sns_plt.axes.set_title(arousal_signal + ' - Important Features', fontsize=36)\n",
    "    \n",
    "    sns_plt.set_xlabel('Feature Importance Score', fontsize=36)\n",
    "    sns_plt.set_ylabel('Features', fontsize=36)\n",
    "\n",
    "    sns_plt.tick_params(labelsize=24)\n",
    "#     sns_plt.set_xticklabels(sns_plt.get_xticklabels(), fontsize = 24)\n",
    "    sns_plt.set_yticklabels(sns_plt.get_yticklabels(), fontsize = 24, rotation = 30)\n",
    "\n",
    "    plt.savefig(all_studies_fig_dir + study_combination + '_' + arousal_signal.lower() + '_feature_importance.png')\n",
    "    plt.savefig(all_studies_fig_dir + study_combination + '_' + arousal_signal.lower() + '_feature_importance.pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# def get_correlation_plot(train_df, arousal_signal, selected_model_features):\n",
    "#     cor_df = train_df.copy()[['Arousal_Mode'] + selected_model_features]\n",
    "#     corr = cor_df.corr().round(3)\n",
    "\n",
    "#     reset_plt()\n",
    "#     plt.figure(figsize=(40, 40))\n",
    "#     plt.subplot(1, 1, 1)\n",
    "    \n",
    "#     sns_plt = sns.heatmap(corr, cmap='YlGnBu', center=0, square=True, linewidths=.5, annot=True, annot_kws={'size': 24})\n",
    "#     sns_plt.collections[0].colorbar.ax.tick_params(labelsize=32)\n",
    "\n",
    "#     sns_plt.set_xticklabels(sns_plt.get_yticklabels(), rotation = 45, fontsize = 38)\n",
    "#     sns_plt.set_yticklabels(sns_plt.get_yticklabels(), rotation = 0, fontsize = 38) \n",
    "    \n",
    "# #     plt.savefig(figure_path + arousal_signal.lower() + '_correlation_plot.png')\n",
    "# #     plt.savefig(figure_path + arousal_signal.lower() + '_correlation_plot.pdf')\n",
    "    \n",
    "#     plt.show()\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred) \n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "    \n",
    "    \n",
    "def get_metrics(model, X_test, y_test, y_pred, y_prob=[]):\n",
    "    Accuracy = get_round(accuracy_score(y_test, y_pred))\n",
    "    F1 = get_round(f1_score(y_test, y_pred, average='weighted'))\n",
    "    Recall = get_round(recall_score(y_test, y_pred, average='weighted'))\n",
    "    Precision = get_round(precision_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "###############################################################################   \n",
    "#     if not len(y_prob): \n",
    "#         if discard_neutral:\n",
    "#             y_prob = model.predict_proba(X_test)[:, 1]\n",
    "#         else:\n",
    "#             y_prob = model.predict_proba(X_test)\n",
    "#             y_prob_ = np.argmax(model.predict_proba(X_test), axis=1).ravel()\n",
    "\n",
    "            \n",
    "#     if discard_neutral:\n",
    "#         # Ref: https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n",
    "#         AUC = get_round(roc_auc_score(y_test, y_prob))\n",
    "\n",
    "#         tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#         Specificity = get_round(tn / (tn+fp)) \n",
    "        \n",
    "#     else:\n",
    "#         # AUC = roc_auc_score(y_test, y_prob, multi_class=\"ovr\")\n",
    "#         AUC = multiclass_roc_auc_score(y_test, y_pred)\n",
    "\n",
    "#         # AUC = 0\n",
    "#         Specificity = 0\n",
    "###############################################################################      \n",
    "        \n",
    "    \n",
    "###############################################################################\n",
    "    AUC = multiclass_roc_auc_score(y_test, y_pred)\n",
    "    # AUC = 0\n",
    "    Specificity = 0\n",
    "###############################################################################\n",
    "\n",
    "        \n",
    "    return Accuracy, AUC, F1, Recall, Precision, Specificity\n",
    "    \n",
    "    \n",
    "    \n",
    "def train_model(df, model_features, arousal_signal, model_train_method, study_subjects_test=None):\n",
    "\n",
    "    #####################################################################################\n",
    "    arousal_col = arousal_signal + '_Arousal_Mode'\n",
    "\n",
    "    # 'PP_Arousal_Mode', 'HR_Arousal_Mode', 'BR_Arousal_Mode'\n",
    "    # 'PP_HR_Arousal_Mode', 'HR_BR_Arousal_Mode', 'PP_HR_BR_Arousal_Mode'\n",
    "    #####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################\n",
    "    df['Arousal_Mode'] = df[arousal_col]\n",
    "    # print(df.Arousal_Mode.unique())\n",
    "    #####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################\n",
    "    #                               MODELING\n",
    "    #####################################################################################\n",
    "    X_train, y_train, X_test, y_test, train_df, test_df = get_splitted_data(df,\n",
    "                                                                            model_features,\n",
    "                                                                            arousal_signal,\n",
    "                                                                            'Arousal_Mode',\n",
    "                                                                            model_train_method,\n",
    "                                                                            study_subjects_test) \n",
    "    model = get_model()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    ## test_df['Prediction'] = y_pred\n",
    "    \n",
    "    \n",
    "    Accuracy, AUC, F1, Recall, Precision, Specificity = get_metrics(model, X_test, y_test, y_pred)\n",
    "    \n",
    "    model_metrics[arousal_signal]['Train']['Accuracy'].append(Accuracy)\n",
    "    model_metrics[arousal_signal]['Train']['AUC'].append(AUC)\n",
    "    model_metrics[arousal_signal]['Train']['F1'].append(F1)\n",
    "    model_metrics[arousal_signal]['Train']['Recall'].append(Recall)\n",
    "    model_metrics[arousal_signal]['Train']['Precision'].append(Precision)\n",
    "    model_metrics[arousal_signal]['Train']['Specificity'].append(Specificity)\n",
    "    #####################################################################################\n",
    "\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    #                         Feature Importance\n",
    "    #####################################################################################\n",
    "    # if feature_imp: \n",
    "    # if study_combination=='sim1' and arousal_signal=='PP_BR':\n",
    "    #     get_feature_importance(model, X_train)\n",
    "    #####################################################################################\n",
    "                               \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################################################################                                                         \n",
    "    # get_confusion_matrix(arousal_signal, y_test, y_pred, do_normalize=True)\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     #####################################################################################\n",
    "#     plot_roc_curve(model, X_test, y_test)\n",
    "    \n",
    "# #     plt.savefig(figure_path + arousal_signal.lower() + '_roc_curve.png')\n",
    "# #     plt.savefig(figure_path + arousal_signal.lower() + '_roc_curve.pdf')\n",
    "    \n",
    "#     plt.show()\n",
    "#     #####################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    #                              PLOTTING\n",
    "    #####################################################################################\n",
    "    ### get_all_confusion_matrices(arousal_signal, train_df, test_df, y_test, y_pred)\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #####################################################################################\n",
    "#     #                        Classification Probabilities\n",
    "#     #####################################################################################\n",
    "#     y_pred_probabilities = model.predict_proba(X_test)\n",
    "#     # print(y_pred_probabilities)\n",
    "    \n",
    "#     test_df['Relaxed_Prob'], test_df['Stress_Prob'] = y_pred_probabilities[:,0], y_pred_probabilities[:,1]\n",
    "# #     test_df.to_csv('../../data/??/' + arousal_signal.lower() + '_pred_result_df.csv', sep=',')\n",
    "    \n",
    "    \n",
    "# #     test_df_mean = test_df[['Prediction', 'Relaxed_Prob', 'Stress_Prob']].groupby(['Prediction']).agg({'Relaxed_Prob': 'mean', 'Stress_Prob': 'mean'})\n",
    "# #     test_df_mean = test_df_mean.apply(lambda x: round(100 * x, 2))\n",
    "# #     print(test_df_mean, '\\n')\n",
    "#     #####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "396fdb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(df, arousal_signal):\n",
    "    \n",
    "    # print('----------------------------------------> Train Studies: ' + str(df.Study_Name.unique()))\n",
    "    \n",
    "    if model_train_method == 'kfold':\n",
    "        study_subjects = np.array(df.Study_Subject.unique())\n",
    "        # print(study_subjects)\n",
    "        for i, indices in enumerate(KFold(n_splits=k_fold_n_splits).split(study_subjects)):\n",
    "            print('Running ' + str(k_fold_n_splits) + '-fold iteration: ' + str(i+1) + '\\n')\n",
    "            train_model(df, model_features, arousal_signal, model_train_method, study_subjects[indices[1]])\n",
    "            # print(model_metrics)\n",
    "\n",
    "\n",
    "######################################################################################$$$$$$$$$$$$$$            \n",
    "#     else:\n",
    "#         if model_train_method == 'best_accurate':\n",
    "#             _range = 1\n",
    "#             random_selection = False\n",
    "#         elif model_train_method == 'bootstrap':\n",
    "#             _range = 30\n",
    "#             random_selection = True\n",
    "            \n",
    "#         for i in range(_range):\n",
    "#             # print('\\n--------------------------------------------- Iteration: ', i+1)\n",
    "#             train_model(df, model_features, arousal_signal, model_train_method)\n",
    "######################################################################################$$$$$$$$$$$$$$            \n",
    "            \n",
    "        \n",
    "    \n",
    "    model = get_model()\n",
    "    model.fit(df[model_features], df[arousal_signal + '_Arousal_Mode'])\n",
    "\n",
    "\n",
    "    print_metrics(model_metrics)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, test_study, test_df, arousal_signal):\n",
    "    X_test = test_df[model_features]\n",
    "    y_test = test_df[arousal_signal + '_Arousal_Mode']\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    prediction_df = test_df.copy()\n",
    "    prediction_df['Prediction'] = y_pred\n",
    "    \n",
    "    Accuracy, AUC, F1, Recall, Precision, Specificity = get_metrics(model, X_test, y_test, y_pred)\n",
    "    \n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Accuracy'] = Accuracy\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['AUC'] = AUC\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['F1'] = F1\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Recall'] = Recall\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Precision'] = Precision\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Specificity'] = Specificity\n",
    "    \n",
    "    if print_all: print('Accuracy: %.2f \\nAUC: %.2f \\nF1: %.2f \\nRecall: %.2f \\nPrecision: %.2f \\nSpecificity: %.2f\\n' % (Accuracy, AUC, F1, Recall, Precision, Specificity))\n",
    "\n",
    "        # print('Accuracy:' + str(Accuracy))\n",
    "        # print('AUC: ' + str(AUC))\n",
    "        # print('F1: ' + str(F1))\n",
    "        # print('Recall: ' + str(Recall))\n",
    "        # print('Precision: ' + str(Precision))\n",
    "        # print('Specificity: ' + str(Specificity))\n",
    "        # print('\\n')\n",
    "        \n",
    "        \n",
    "    return prediction_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64b202a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model_metrics):\n",
    "    print('\\nAvg. k-fold metrics: ----> ')\n",
    "\n",
    "    for metric in ['Accuracy', 'AUC', 'F1', 'Recall', 'Precision', 'Specificity']:\n",
    "    # for metric in ['Accuracy', 'F1', 'Recall', 'Precision']:\n",
    "        metric_numbers = model_metrics[arousal_signal]['Train'][metric]\n",
    "\n",
    "        try:\n",
    "            if model_train_method == 'best_accurate':\n",
    "                print(metric + ': ' + get_rounded_str(metric_numbers[0], 2))\n",
    "            elif model_train_method == 'bootstrap':\n",
    "                print(metric + ': ' + \n",
    "                      get_rounded_str(mean(metric_numbers), 2) + u' \\u00B1 ' +\n",
    "                      get_rounded_str(stdev(metric_numbers), 3))\n",
    "            elif model_train_method == 'kfold':\n",
    "                metric_val = get_round(mean(metric_numbers), 2)\n",
    "                model_metrics[arousal_signal]['K_Fold'][metric] = metric_val\n",
    "                print(metric + ': ' + get_rounded_str(metric_val, 2))\n",
    "        except Exception as e:\n",
    "            model_metrics[arousal_signal]['K_Fold'][metric] = None\n",
    "            # print('Error occured for %s : %s' % (metric, str(e)))\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6474bacd-cd50-4502-aab6-83844b67d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_df():\n",
    "    metric_df = {}\n",
    "\n",
    "    for col in metrics_df.columns:\n",
    "        metric_df[col] = None\n",
    "     \n",
    "    return metric_df\n",
    "\n",
    "\n",
    "\n",
    "def get_test_study_metrics_df(arousal_signal, study_combination, test_study, model_metrics, k_fold=True):\n",
    "\n",
    "    metric_df = get_metric_df()\n",
    "    metric_df['Model'] = model_name\n",
    "    metric_df['Arousal_Signal'] = arousal_signal\n",
    "    metric_df['Train_Study'] = study_combination\n",
    "    metric_df['Test_Study'] = test_study\n",
    "    \n",
    "    model_metric = 'K_Fold' if k_fold else 'Train'\n",
    "\n",
    "    for metric in all_metrics.keys():\n",
    "        metric_df['Train_' + metric] = model_metrics[arousal_signal][model_metric][metric]\n",
    "        if test_study: metric_df['Test_' + metric] = model_metrics[arousal_signal]['Test'][test_study.upper()][metric]\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428beb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4980d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overleaf_cols_name(study_name):\n",
    "    return study_name.replace('_', ' ').upper()\n",
    "\n",
    "def get_overleaf_modality_name(modality):\n",
    "    if modality == 'PP':\n",
    "        return 'PP\\\\textsubscript{NS}'\n",
    "    elif modality == 'PP_2':\n",
    "        return 'PP\\\\textsubscript{N}'\n",
    "    elif modality == 'HR':\n",
    "        return 'HR\\\\textsubscript{N}'\n",
    "    elif modality == 'BR':\n",
    "        return 'BR\\\\textsubscript{N}'\n",
    "#     elif modality == 'PP_BR':\n",
    "#         return 'PP\\_BR\\\\textsubscript{N}'\n",
    "    \n",
    "    return modality.replace('_', '\\_')\n",
    "    \n",
    "\n",
    "    \n",
    "def get_overleaf_metrics(model_metrics, test_studies, modality, metric):\n",
    "    metrics = []\n",
    "\n",
    "    metrics.append(model_metrics[modality]['K_Fold'][metric])\n",
    "    for test_study in test_studies:\n",
    "        metrics.append(model_metrics[modality]['Test'][test_study][metric])\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def get_overleaf_table(study_combination, model_metrics):\n",
    "    metric_names = all_metrics if overleaf_metrics else ['AUC', 'F1']\n",
    "    \n",
    "    \n",
    "    modalities = list(model_metrics.keys())\n",
    "    test_studies = list(model_metrics[list(model_metrics.keys())[0]]['Test'].keys())\n",
    "    total_test_studies = len(test_studies)\n",
    "    \n",
    "    table_begin_str = '\\\\begin{center} \\n\\\\begin{tabular}\\n'\n",
    "    table_cols_attr = '{|p{2cm}|' +  'p{3.5cm}|'*(total_test_studies+1) + '} \\hline \\n'\n",
    "    table_cols_name = '& \\\\textbf{' + get_overleaf_cols_name(study_combination) + ' - ' + str(k_fold_n_splits) + '-Fold' + '} '\n",
    "    table_cols_name += ''.join(['& \\\\textbf{Test on '+ get_overleaf_cols_name(test_study) +'} ' for test_study in test_studies]) \n",
    "    table_cols_name += '\\\\\\\\ \\hline \\hline \\n'\n",
    "    table_end_str = '\\end{tabular} \\n\\end{center} \\n'\n",
    "\n",
    "    table_row_metrics = ''\n",
    "    for modality in modalities:\n",
    "        table_row_metrics += '\\multirow{' + str(len(metric_names)) + '}{1em}{\\emph{' + get_overleaf_modality_name(modality) + '}}'\n",
    "        \n",
    "        for metric_name in metric_names:\n",
    "            metrics = get_overleaf_metrics(model_metrics, test_studies, modality, metric_name)\n",
    "            table_row_metrics += ''.join([(' & ' + metric_name + ': ' + str(metric_val)) for metric_val in metrics]) + ' \\\\\\\\ \\n'\n",
    "            \n",
    "        table_row_metrics += ' \\hline \\n\\n'\n",
    "    \n",
    "    overleaf_table = table_begin_str + table_cols_attr + table_cols_name + table_row_metrics + table_end_str\n",
    "    return overleaf_table\n",
    "\n",
    "\n",
    "\n",
    "# get_overleaf_table('sim1', ['sim2', 'tt1', 'office_task'], model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767d8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64a9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d5bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c9b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c11f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35bb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a07616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1c414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39a914bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_plt():\n",
    "    plt.figure().clear()\n",
    "    plt.close()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    \n",
    "    sns.set_context('paper', rc={'font.size': 16,\n",
    "                                 'axes.titlesize': 24,\n",
    "                                 'axes.labelsize': 16}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01641274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_plot():\n",
    "    #################\n",
    "    # DO NOT DELETE #\n",
    "    #################\n",
    "\n",
    "\n",
    "\n",
    "    ##################################\n",
    "    ####----   Old Features   ----####\n",
    "    ##################################\n",
    "    # cor_df = train_df.copy()[['Arousal_Mode',\n",
    "    #                           'PP_Mean', 'PP_SD', 'PP_Median', 'PP_SS', \n",
    "    #                           'Palm_Mean', 'Palm_SD', 'Palm_Median', 'Palm_SS', \n",
    "    #                           'Hr_Mean', 'Hr_SD', 'Hr_Median', 'Hr_SS', \n",
    "    #                           'Br_Mean', 'Br_SD', 'Br_Median', 'Br_SS',\n",
    "    #                           'Treatment_Label_CD', 'Treatment_Label_ED', \n",
    "    #                           'Treatment_Label_FD', 'Treatment_Label_MD'\n",
    "    #                            ]]\n",
    "\n",
    "\n",
    "    #############################################\n",
    "    ####---- only physiological Features ----####\n",
    "    #############################################\n",
    "    # cor_df = train_df.copy()[['Arousal_Mode', \n",
    "    #                           'PP_Mean', 'PP_SD',\n",
    "    #                           'Palm_Mean', 'Palm_SD', \n",
    "    #                           'Hr_Mean', 'Hr_SD',\n",
    "    #                           'Br_Mean', 'Br_SD',\n",
    "    #                           'Treatment_Label_CD', 'Treatment_Label_ED', \n",
    "    #                           'Treatment_Label_FD', 'Treatment_Label_MD'\n",
    "    #                            ]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ###################################\n",
    "    # ####----   Plot Features   ----####\n",
    "    # ###################################\n",
    "    # cor_df = plot_df.copy()[['Arousal_Mode'] + plot_features]\n",
    "    # corr = cor_df.corr().round(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #################################\n",
    "    ###----   All Features   ----####\n",
    "    #################################\n",
    "    cor_df = train_df.copy()[['Arousal_Mode'] + model_features]\n",
    "    corr = cor_df.corr().round(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##################################################################\n",
    "    reset_plt()\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    plt.subplot(1, 1, 1)\n",
    "\n",
    "    sns_plt = sns.heatmap(corr, cmap='YlGnBu', center=0, square=True, linewidths=.5, annot=True, annot_kws={'size': 24})\n",
    "    sns_plt.collections[0].colorbar.ax.tick_params(labelsize=32)\n",
    "\n",
    "    sns_plt.set_xticklabels(sns_plt.get_xticklabels(), rotation = 45, fontsize = 34, ha='right')  # 45\n",
    "    sns_plt.set_yticklabels(sns_plt.get_yticklabels(), rotation = 0, fontsize = 34)\n",
    "\n",
    "\n",
    "    # sns_plt.axes.set_title('Title',fontsize=50)\n",
    "    # sns_plt.set_xlabel('X Label',fontsize=30)\n",
    "    # sns_plt.set_ylabel('Y Label',fontsize=20)\n",
    "    # sns_plt.tick_params(labelsize=5)\n",
    "    # sns_plt.plt.show()\n",
    "\n",
    "\n",
    "#     plt.savefig(figure_path + 'all_features_correlation_plot.png')\n",
    "#     plt.savefig(figure_path + 'all_features_correlation_plot.pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4849b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f196fb62-dba0-4b8a-b4d6-95174c0184c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://cmdlinetips.com/2019/05/empirical-cumulative-distribution-function-ecdf-in-python/\n",
    "def generate_ecdf_plots(df, idx):\n",
    "    if idx == 0:\n",
    "        signal = 'PP'\n",
    "        title = '$ln PP - \\overline{ln PP}_{BL} [ln ^{o}c^{2}]$'\n",
    "        # title = '$ln PP - \\overline{ln PP}_{BL} + 0.5 SD [ln ^{o}c^{2}]$'\n",
    "        \n",
    "    # elif idx == 1:\n",
    "    #     col = 'PP_2'\n",
    "    #     title = '$ln PP - \\overline{ln PP}_{BL} [ln ^{o}c^{2}]$'\n",
    "        \n",
    "    elif idx == 1:\n",
    "        signal = 'HR'\n",
    "        title = '$HR - \\overline{HR}_{BL} [BPM]$'\n",
    "        \n",
    "    elif idx == 2:\n",
    "        signal = 'BR'\n",
    "        title = '$BR - \\overline{BR}_{BL} [BPM]$'\n",
    "        \n",
    "    \n",
    "    col = signal + '_Normalized'\n",
    "    ecdf_col = signal + '_ecdf'\n",
    "    \n",
    "    df[ecdf_col] = df[col].rank(method='max').div(df[col].count())\n",
    "    \n",
    "    sorted_values = np.sort(df[col])\n",
    "    probabilty = np.sort(df[ecdf_col])\n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    # n = sorted_values.size\n",
    "    # probabilty_2 = np.arange(1, n+1) / n\n",
    "      \n",
    "    # print(np.array_equal(probabilty, probabilty_2))\n",
    "    ###########################################\n",
    "      \n",
    "\n",
    "    plt.scatter(x=sorted_values, y=probabilty);\n",
    "    plt.xlabel('   ', fontsize=4)\n",
    "    plt.ylabel('ECDF', fontsize=16)\n",
    "    plt.title(label=title, fontsize=40)\n",
    "    \n",
    "    return df    \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "def generate_arousal_extraction_plots(df, idx):\n",
    "    if idx == 0:\n",
    "        x_axis = 'PP_Normalized'\n",
    "        y_axis = 'PP_Arousal'\n",
    "        title = '$ln PP - \\overline{ln PP}_{BL} + 0.5 SD [ln ^{o}c^{2}]$'\n",
    "        \n",
    "        diff_mean = pp_diff_mean\n",
    "        diff_sd = pp_diff_sd\n",
    "        \n",
    "    elif idx == 1:\n",
    "        x_axis = 'PP_Normalized'\n",
    "        y_axis = 'PP_Arousal_2'\n",
    "        title = '$ln PP - \\overline{ln PP}_{BL} [ln ^{o}c^{2}]$'\n",
    "        \n",
    "        diff_mean = pp_diff_mean\n",
    "        diff_sd = pp_diff_sd\n",
    "        \n",
    "    elif idx == 2:\n",
    "        x_axis = 'HR_Normalized'\n",
    "        y_axis = 'HR_Arousal'\n",
    "        title = '$HR - \\overline{HR}_{BL} [BPM]$'\n",
    "        \n",
    "        diff_mean = hr_diff_mean\n",
    "        diff_sd = hr_diff_sd\n",
    "        \n",
    "    elif idx == 3:\n",
    "        x_axis = 'BR_Normalized'\n",
    "        y_axis = 'BR_Arousal'\n",
    "        title = '$BR - \\overline{BR}_{BL} [BPM]$'\n",
    "        \n",
    "        diff_mean = br_diff_mean\n",
    "        diff_sd = br_diff_sd\n",
    "        \n",
    "        \n",
    "    sns_plot = sns.histplot(data=df, \n",
    "                 x=x_axis, \n",
    "                 hue=y_axis, \n",
    "                 palette=palette)\n",
    "    \n",
    "    sns_plot.set(title=title,\n",
    "                xlabel='   ',\n",
    "                ylabel='   ',\n",
    "                yticks=[])\n",
    "\n",
    "    plt.axvline(diff_mean, color='red', lw=line_width)\n",
    "\n",
    "    plt.axvline(diff_mean + diff_sd, color='black', lw=line_width)\n",
    "    plt.axvline(diff_mean + 2*diff_sd, color='black', lw=line_width)\n",
    "    plt.axvline(diff_mean - diff_sd, color='black', lw=line_width)\n",
    "    plt.axvline(diff_mean - 2*diff_sd, color='black', lw=line_width)\n",
    "\n",
    "    plt.axvline(diff_mean - 0.5*diff_sd, color='gray', lw=line_width)\n",
    "    plt.axvline(diff_mean + 0.5*diff_sd, color='gray', lw=line_width)\n",
    "\n",
    "    plt.legend().set_visible(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ee5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b723576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorator = '----------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad2a1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_subjs(arousal_signal):\n",
    "    \n",
    "#     ######################################\n",
    "#     # 'PP', 'PP_2', 'HR', 'BR', 'PP_HR_BR'\n",
    "#     ######################################\n",
    "    \n",
    "#     if arousal_signal == 'PP':\n",
    "#         #####################################\n",
    "#         # return [2, 31, 66, 47, 44, 25, 24]\n",
    "#         #####################################\n",
    "#         return [18, 23, 16, 25, 8, 45, 2]\n",
    "    \n",
    "#     elif arousal_signal == 'PP_2':\n",
    "#         return [44, 20, 16, 68, 33, 60, 18]\n",
    "    \n",
    "#     elif arousal_signal == 'HR':\n",
    "#         return [61, 29, 24, 38, 84, 2, 17]\n",
    "    \n",
    "#     elif arousal_signal == 'BR':\n",
    "#         return [44, 62, 81, 20, 61, 38, 79]\n",
    "    \n",
    "#     elif arousal_signal == 'PP_HR_BR':\n",
    "#         return [31, 66, 16, 29, 62, 44, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e1cf6",
   "metadata": {},
   "source": [
    "# Standardized Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a6a3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_df(files):\n",
    "    for file in files:\n",
    "        scaled_df = pd.DataFrame()\n",
    "        df = pd.read_csv(all_studies_data_dir + file)\n",
    "        \n",
    "        for study in df.Study_Name.unique():\n",
    "            print(file, study)\n",
    "            study_df = df.copy()[df.Study_Name == study]\n",
    "            ###################################################################################################\n",
    "            for feature in model_features:\n",
    "                study_df[feature] = StandardScaler().fit_transform(study_df[[feature]])\n",
    "            ###################################################################################################\n",
    "\n",
    "            scaled_df = scaled_df.append(study_df)\n",
    "\n",
    "        scaled_df.to_csv(all_studies_data_dir + file[:-4]+'_scaled.csv', sep=',', index=False)\n",
    "    \n",
    "    \n",
    "# 'data_7_w30_10.csv'[:-4]+'_scaled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138419b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af0ee2e8",
   "metadata": {},
   "source": [
    "# Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71e73111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_post_processed_aggregrated_df(aggregrated_df):\n",
    "#     aggregrated_df = pd.get_dummies(aggregrated_df, columns=['Gender'])\n",
    "#     aggregrated_df = rename_cols(aggregrated_df)\n",
    "    \n",
    "# ###########################################################################################    \n",
    "# #     aggregrated_df['PP_HR_Arousal_Mode'] = np.where((aggregrated_df['PP_Arousal_Mode'] == aggregrated_df['HR_Arousal_Mode']) &\n",
    "# #                                           (aggregrated_df['PP_Arousal_Mode'] == 'stressed'), \n",
    "# #                                            'stressed', 'relaxed')\n",
    "\n",
    "\n",
    "# #     aggregrated_df['PP_BR_Arousal_Mode'] = np.where((aggregrated_df['PP_Arousal_Mode'] == aggregrated_df['BR_Arousal_Mode']) &\n",
    "# #                                               (aggregrated_df['PP_Arousal_Mode'] == 'stressed'), \n",
    "# #                                                'stressed', 'relaxed')\n",
    "\n",
    "\n",
    "# #     aggregrated_df['HR_BR_Arousal_Mode'] = np.where((aggregrated_df['HR_Arousal_Mode'] == aggregrated_df['BR_Arousal_Mode']) &\n",
    "# #                                               (aggregrated_df['HR_Arousal_Mode'] == 'stressed'), \n",
    "# #                                                'stressed', 'relaxed')\n",
    "\n",
    "\n",
    "# #     aggregrated_df['PP_HR_BR_Arousal_Mode'] = aggregrated_df[['PP_Arousal_Mode',\n",
    "# #                                               'HR_Arousal_Mode',\n",
    "# #                                               'BR_Arousal_Mode']].mode(axis=1)[0] \n",
    "# ###########################################################################################    \n",
    "    \n",
    "#     aggregrated_df.dropna(inplace=True)\n",
    "#     return aggregrated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98537b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_single_window_aggregrated_df(single_sec_df, window_size=10, rolling_window=False):\n",
    "#     next_idx = window_size//2 if rolling_window else window_size\n",
    "#     aggregrated_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "#     for study in single_sec_df.Study_Name.unique():\n",
    "#         study_df = single_sec_df.copy()[single_sec_df.Study_Name == study]\n",
    "\n",
    "#         # for subj in study_df.Subject.unique():\n",
    "#         for subj in study_df.Subject.unique()[:1]:\n",
    "\n",
    "#             print(study, subj)\n",
    "#             study_subj_df = study_df.copy()[study_df.Subject == subj]\n",
    "\n",
    "#             for treatment in study_subj_df.Treatment.unique():\n",
    "#                 treatment_df = study_subj_df.copy()[study_subj_df.Treatment == treatment]\n",
    "\n",
    "#                 i = 0\n",
    "#                 totalRows = treatment_df.shape[0]\n",
    "\n",
    "#                 while i+window_size < totalRows:\n",
    "#                     treatment_agg_df = treatment_df.copy().iloc[i: min(totalRows, i+window_size)]\n",
    "#                     first_row = treatment_agg_df.iloc[0]\n",
    "#                     i += next_idx\n",
    "\n",
    "#                     temp_df = pd.DataFrame({\n",
    "#                         'Study_Name': [first_row.Study_Name], \n",
    "#                         'Subject': [first_row.Subject], \n",
    "#                         'Study_Subject': [first_row.Study_Subject], \n",
    "#                         'Treatment': [first_row.Treatment],\n",
    "#                         'Gender': [first_row.Gender],\n",
    "#                         'Age': [first_row.Age],\n",
    "#                         'NASA_Effort': [first_row.NASA_Effort],\n",
    "#                         'NASA_Frustration': [first_row.NASA_Frustration],\n",
    "#                         'NASA_Mental': [first_row.NASA_Mental],\n",
    "#                         'NASA_Performance': [first_row.NASA_Performance],\n",
    "#                         'NASA_Physical': [first_row.NASA_Physical],\n",
    "#                         'NASA_Temporal': [first_row.NASA_Temporal],\n",
    "#                         'NASA_Total': [first_row.NASA_Total],\n",
    "#                     })\n",
    "\n",
    "#                     temp_df['PP_Arousal_Mode'] = treatment_agg_df.PP_Arousal.mode()\n",
    "#                     temp_df['PP_2_Arousal_Mode'] = treatment_agg_df.PP_Arousal_2.mode()\n",
    "#                     temp_df['HR_Arousal_Mode'] = treatment_agg_df.HR_Arousal.mode()\n",
    "#                     temp_df['BR_Arousal_Mode'] = treatment_agg_df.BR_Arousal.mode()\n",
    "\n",
    "#                     temp_df['PP_Mean'] = treatment_agg_df.Perinasal_Log.mean()\n",
    "#                     temp_df['PP_Median'] = treatment_agg_df.Perinasal_Log.median()\n",
    "#                     temp_df['PP_SD'] = stdev(treatment_agg_df.Perinasal_Log)\n",
    "#                     temp_df['PP_SS'] = sum_of_squares(treatment_agg_df.Perinasal_Log)\n",
    "\n",
    "#                     temp_df['HR_Mean'] = treatment_agg_df.Heart.mean()\n",
    "#                     temp_df['HR_Median'] = treatment_agg_df.Heart.median()\n",
    "#                     temp_df['HR_SD'] = stdev(treatment_agg_df.Heart)\n",
    "#                     temp_df['HR_SS'] = sum_of_squares(treatment_agg_df.Heart)\n",
    "\n",
    "#                     temp_df['BR_Mean'] = treatment_agg_df.Breathing.mean()\n",
    "#                     temp_df['BR_Median'] = treatment_agg_df.Breathing.median()\n",
    "#                     temp_df['BR_SD'] = stdev(treatment_agg_df.Breathing)\n",
    "#                     temp_df['BR_SS'] = sum_of_squares(treatment_agg_df.Breathing)\n",
    "                    \n",
    "#                     pd.get_dummies(final_df, columns=['Gender'])\n",
    "\n",
    "#                     aggregrated_df = aggregrated_df.append(temp_df)\n",
    "\n",
    "#     return get_post_processed_aggregrated_df(aggregrated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd66ffa7-e2d7-40d3-ab54-abbab26128ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist_arousal_voting(df):\n",
    "    \n",
    "    #####################################################################################################################\n",
    "    #                                   Any Modality Stress\n",
    "    #####################################################################################################################\n",
    "    # df['PP_HR_Arousal_Mode'] = np.where((df['PP_Arousal_Mode'] == 'stressed') |\n",
    "    #                                           (df['HR_Arousal_Mode'] == 'stressed'), \n",
    "    #                                            'stressed', 'relaxed')\n",
    "\n",
    "    # df['PP_BR_Arousal_Mode'] = np.where((df['PP_Arousal_Mode'] == 'stressed') |\n",
    "    #                                           (df['BR_Arousal_Mode'] == 'stressed'), \n",
    "    #                                            'stressed', 'relaxed')\n",
    "\n",
    "    # df['HR_BR_Arousal_Mode'] = np.where((df['HR_Arousal_Mode'] == 'stressed') |\n",
    "    #                                           (df['BR_Arousal_Mode'] == 'stressed'), \n",
    "    #                                            'stressed', 'relaxed')\n",
    "\n",
    "    # df['PP_HR_BR_Arousal_Mode'] = np.where((df['PP_Arousal_Mode'] == 'stressed') |\n",
    "    #                                                   (df['HR_Arousal_Mode'] == 'stressed') |\n",
    "    #                                                   (df['BR_Arousal_Mode'] == 'stressed'),\n",
    "    #                                                   'stressed', 'relaxed')\n",
    "    #####################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "#     #####################################################################################################################\n",
    "#     #                                   Two Modalities Stressed (Majority Votes for Stress)\n",
    "#     #####################################################################################################################\n",
    "#     df['PP_HR_Arousal_Mode_Hist'] = np.where((df['PP_Arousal_Mode_Hist'] == df['HR_Arousal_Mode_Hist']) &\n",
    "#                                               (df['PP_Arousal_Mode_Hist'] == 'stressed'), \n",
    "#                                                'stressed', 'relaxed')\n",
    "\n",
    "#     df['PP_BR_Arousal_Mode_Hist'] = np.where((df['PP_Arousal_Mode_Hist'] == df['BR_Arousal_Mode_Hist']) &\n",
    "#                                               (df['PP_Arousal_Mode_Hist'] == 'stressed'), \n",
    "#                                                'stressed', 'relaxed')\n",
    "\n",
    "#     df['HR_BR_Arousal_Mode_Hist'] = np.where((df['HR_Arousal_Mode_Hist'] == df['BR_Arousal_Mode_Hist']) &\n",
    "#                                               (df['HR_Arousal_Mode_Hist'] == 'stressed'), \n",
    "#                                                'stressed', 'relaxed')\n",
    "\n",
    "#     df['PP_HR_BR_Arousal_Mode_Hist'] = df[['PP_Arousal_Mode_Hist',\n",
    "#                                            'HR_Arousal_Mode_Hist',\n",
    "#                                            'BR_Arousal_Mode_Hist']].mode(axis=1)[0] \n",
    "#     #####################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################################################\n",
    "    #                        ECDF - Two Modalities Stressed (Majority Votes for Stress)\n",
    "    #####################################################################################################################\n",
    "    # df['PP_HR_Arousal_Mode'] = np.where((df['PP_Arousal_Mode'] == df['HR_Arousal_Mode']), \n",
    "    #                                            df['PP_Arousal_Mode'], 'neutral')\n",
    "\n",
    "    # df['PP_BR_Arousal_Mode'] = np.where((df['PP_Arousal_Mode'] == df['BR_Arousal_Mode']), \n",
    "    #                                            df['PP_Arousal_Mode'], 'neutral')\n",
    "\n",
    "    # df['HR_BR_Arousal_Mode'] = np.where((df['HR_Arousal_Mode'] == df['BR_Arousal_Mode']), \n",
    "    #                                            df['BR_Arousal_Mode'], 'neutral')\n",
    "\n",
    "    # df['PP_HR_BR_Arousal_Mode'] = df[['PP_Arousal_Mode',\n",
    "    #                                               'HR_Arousal_Mode',\n",
    "    #                                               'BR_Arousal_Mode']].mode(axis=1)[0] \n",
    "    #####################################################################################################################\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_arousal_cols(df):\n",
    "    \n",
    "        df = get_hist_arousal_voting(df)\n",
    "    \n",
    "        df.rename(columns = {\n",
    "            # 'PP_Arousal_Mode_Hist': 'PP_Arousal_Mode',\n",
    "            # 'HR_Arousal_Mode_Hist': 'HR_Arousal_Mode',\n",
    "            # 'BR_Arousal_Mode_Hist': 'BR_Arousal_Mode',\n",
    "            \n",
    "            # 'PP_HR_Arousal_Mode_Hist': 'PP_HR_Arousal_Mode',\n",
    "            # 'PP_BR_Arousal_Mode_Hist': 'PP_BR_Arousal_Mode',\n",
    "            # 'HR_BR_Arousal_Mode_Hist': 'HR_BR_Arousal_Mode',\n",
    "            # 'PP_HR_BR_Arousal_Mode_Hist': 'PP_HR_BR_Arousal_Mode',\n",
    "\n",
    "            'PP_Arousal_Mode_ecdf': 'PP_Arousal_Mode',\n",
    "            'HR_Arousal_Mode_ecdf': 'HR_Arousal_Mode',\n",
    "            'BR_Arousal_Mode_ecdf': 'BR_Arousal_Mode',\n",
    "            \n",
    "            'PP_HR_Arousal_Mode_ecdf': 'PP_HR_Arousal_Mode',\n",
    "            'PP_BR_Arousal_Mode_ecdf': 'PP_BR_Arousal_Mode',\n",
    "            'HR_BR_Arousal_Mode_ecdf': 'HR_BR_Arousal_Mode',\n",
    "            'PP_HR_BR_Arousal_Mode_ecdf': 'PP_HR_BR_Arousal_Mode',\n",
    "\n",
    "        }, inplace=True)\n",
    "\n",
    "        print_percentage(df, 'PP_Arousal_Mode')\n",
    "        print_percentage(df, 'HR_Arousal_Mode')\n",
    "        print_percentage(df, 'BR_Arousal_Mode')\n",
    " \n",
    "        print_percentage(df, 'PP_HR_Arousal_Mode')\n",
    "        print_percentage(df, 'PP_BR_Arousal_Mode')\n",
    "        print_percentage(df, 'HR_BR_Arousal_Mode')\n",
    "        print_percentage(df, 'PP_HR_BR_Arousal_Mode')\n",
    "        \n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467c174-58a1-4646-b484-11f6162aaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecdf_arousal_cols(df, signals):\n",
    "    \n",
    "    combined_signals=[]\n",
    "    for i in range(2, 4):\n",
    "        for signal_subset in itertools.combinations(signals, i):\n",
    "            combined_signal = '_'.join(signal_subset) \n",
    "            combined_signals.append(combined_signal)\n",
    "            df[combined_signal+'_ecdf'] = df[[signal+'_ecdf' for signal in signal_subset]].mean(axis=1)\n",
    "            \n",
    "            # print(signal_subset, combined_signal)\n",
    "            # print([signal+'_ecdf' for signal in signal_subset])\n",
    "             \n",
    "    signals += combined_signals     \n",
    "    \n",
    "    for signal in signals:\n",
    "        df.loc[\n",
    "            df[signal+'_ecdf'] < non_arousal_threshold_ecdf, \n",
    "            signal+'_Arousal_ecdf'] = 'relaxed' # 'non-arousal'\n",
    "\n",
    "        df.loc[\n",
    "            (df[signal+'_ecdf'] >= non_arousal_threshold_ecdf) & \n",
    "            (df[signal+'_ecdf'] < arousal_threshold_ecdf), \n",
    "            signal+'_Arousal_ecdf'] = 'neutral'\n",
    "\n",
    "        df.loc[\n",
    "            df[signal+'_ecdf'] >= arousal_threshold_ecdf, \n",
    "            signal+'_Arousal_ecdf'] = 'stressed' # 'arousal'\n",
    "        \n",
    "        \n",
    "        \n",
    "        if running_study=='sim1':\n",
    "            one_sd_non_arousal = 0.15\n",
    "            one_sd_arousal = 1-one_sd_non_arousal\n",
    "            \n",
    "            df.loc[\n",
    "                df[signal+'_ecdf'] < one_sd_non_arousal, \n",
    "                signal+'_Arousal_ecdf_1sd'] = 'relaxed' # 'non-arousal'\n",
    "\n",
    "            df.loc[\n",
    "                (df[signal+'_ecdf'] >= one_sd_non_arousal) & \n",
    "                (df[signal+'_ecdf'] < one_sd_arousal), \n",
    "                signal+'_Arousal_ecdf_1sd'] = 'neutral'\n",
    "\n",
    "            df.loc[\n",
    "                df[signal+'_ecdf'] >= one_sd_arousal, \n",
    "                signal+'_Arousal_ecdf_1sd'] = 'stressed' # 'arousal'\n",
    "\n",
    "        \n",
    "\n",
    "        print_percentage(df, signal+'_Arousal_ecdf')\n",
    "    \n",
    "     \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697a4b4-debd-4de4-87d0-21c501ca9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f557fe-8556-4414-9703-c8bf5f1240a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_overlapping_aggregrated_df(df):\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # THIS IS NEEDED FOR COMBINED STUDIES\n",
    "    # ------------------------------------------\n",
    "    df = df.copy().rename(columns={\n",
    "         'NASA_Effort': 'Effort',\n",
    "         'NASA_Frustration': 'Frustration', \n",
    "         'NASA_Performance': 'Performance',\n",
    "        \n",
    "         'NASA_Mental': 'Mental Demand',\n",
    "         'NASA_Physical': 'Physical Demand',\n",
    "         'NASA_Temporal': 'Temporal Demand', \n",
    "         'NASA_Total': 'NASA Total Sum',\n",
    "    })\n",
    "\n",
    "    \n",
    "    aggregrated_df = pd.DataFrame()\n",
    "    \n",
    "    print('Subject Processing: ')\n",
    "    # for subj in df.Subject.unique():\n",
    "    for subj in df.Subject.unique()[:8]:\n",
    "        print(subj)\n",
    "        \n",
    "        for treatment in df.Treatment.unique():\n",
    "            subj_treatment_df = df.copy()[(df.Subject == subj) & (df.Treatment == treatment )]\n",
    "\n",
    "            i = 0\n",
    "            totalRows = subj_treatment_df.shape[0]\n",
    "            \n",
    "            while i+2 < totalRows: # proceed for atleast 3 rows\n",
    "                subj_treatment_aggregrated_df = subj_treatment_df.copy().iloc[i: min(totalRows, i+10)]\n",
    "                subj_treatment_window_first_row = subj_treatment_aggregrated_df.iloc[0]\n",
    "                i += 10\n",
    "                \n",
    "                temp_df = pd.DataFrame({'Subject': [subj], \n",
    "                                        'Treatment': [treatment], \n",
    "                                        'Gender': [subj_treatment_window_first_row.Gender],\n",
    "                                        'Age': [subj_treatment_window_first_row.Age],\n",
    "                                        # 'Treatment': [subj_treatment_window_first_row.Treatment],\n",
    "                                        # 'STAI': [subj_treatment_window_first_row.STAI],\n",
    "                                        # 'Type_AB': [subj_treatment_window_first_row.Type_AB],\n",
    "                                        'Effort': [subj_treatment_window_first_row.Effort],\n",
    "                                        'Frustration': [subj_treatment_window_first_row.Frustration],\n",
    "                                        'Mental_Demand': [subj_treatment_window_first_row['Mental Demand']],\n",
    "                                        'Performance': [subj_treatment_window_first_row['Performance']],\n",
    "                                        'Physical_Demand': [subj_treatment_window_first_row['Physical Demand']],\n",
    "                                        'Temporal_Demand': [subj_treatment_window_first_row['Temporal Demand']],\n",
    "                                        'NASA_Total_Sum': [subj_treatment_window_first_row['NASA Total Sum']]\n",
    "                                       })\n",
    "                \n",
    "                # temp_df['PP_Arousal_Mode'] = subj_drive_window_df.PP_Arousal.mode()\n",
    "                # temp_df['PP_2_Arousal_Mode'] = subj_drive_window_df.PP_Arousal_2.mode()\n",
    "                # temp_df['HR_Arousal_Mode'] = subj_drive_window_df.HR_Arousal.mode()\n",
    "                # temp_df['BR_Arousal_Mode'] = subj_drive_window_df.BR_Arousal.mode()\n",
    "                \n",
    "                \n",
    "                # temp_df['PP_Arousal_Mode_Hist'] = subj_treatment_aggregrated_df.PP_Arousal.mode()\n",
    "                # ### temp_df['PP_2_Arousal_Mode_Hist'] = subj_treatment_aggregrated_df.PP_Arousal_2.mode()\n",
    "                # temp_df['HR_Arousal_Mode_Hist'] = subj_treatment_aggregrated_df.HR_Arousal.mode()\n",
    "                # temp_df['BR_Arousal_Mode_Hist'] = subj_treatment_aggregrated_df.BR_Arousal.mode()\n",
    "                \n",
    "                \n",
    "                temp_df['PP_Arousal_Mode_ecdf'] = subj_treatment_aggregrated_df.PP_Arousal_ecdf.mode()\n",
    "                temp_df['HR_Arousal_Mode_ecdf'] = subj_treatment_aggregrated_df.HR_Arousal_ecdf.mode()\n",
    "                temp_df['BR_Arousal_Mode_ecdf'] = subj_treatment_aggregrated_df.BR_Arousal_ecdf.mode()\n",
    "                \n",
    "                if running_study == 'sim1':\n",
    "                    temp_df['PP_Arousal_Mode_1sd'] = subj_treatment_aggregrated_df.PP_Arousal_ecdf_1sd.mode()\n",
    "                    temp_df['HR_Arousal_Mode_1sd'] = subj_treatment_aggregrated_df.HR_Arousal_ecdf_1sd.mode()\n",
    "                    temp_df['BR_Arousal_Mode_1sd'] = subj_treatment_aggregrated_df.BR_Arousal_ecdf_1sd.mode()\n",
    "                \n",
    "                temp_df['PP_HR_Arousal_Mode_ecdf'] = subj_treatment_aggregrated_df.PP_HR_Arousal_ecdf.mode()\n",
    "                temp_df['PP_BR_Arousal_Mode_ecdf'] = subj_treatment_aggregrated_df.PP_BR_Arousal_ecdf.mode()\n",
    "                temp_df['HR_BR_Arousal_Mode_ecdf'] = subj_treatment_aggregrated_df.HR_BR_Arousal_ecdf.mode()\n",
    "                temp_df['PP_HR_BR_Arousal_Mode_ecdf'] = subj_treatment_aggregrated_df.PP_HR_BR_Arousal_ecdf.mode()\n",
    "                \n",
    "                \n",
    "# ###################################################################################################################                \n",
    "#                 temp_df['PP_Mean_NN'] = subj_treatment_aggregrated_df.Perinasal_Log.mean()\n",
    "#                 temp_df['PP_Median_NN'] = subj_treatment_aggregrated_df.Perinasal_Log.median()\n",
    "#                 temp_df['PP_SD_NN'] = stdev(subj_treatment_aggregrated_df.Perinasal_Log)\n",
    "#                 temp_df['PP_SS_NN'] = sum_of_squares(subj_treatment_aggregrated_df.Perinasal_Log)\n",
    "                \n",
    "#                 temp_df['Hr_Mean_NN'] = subj_treatment_aggregrated_df.Heart.mean()\n",
    "#                 temp_df['Hr_Median_NN'] = subj_treatment_aggregrated_df.Heart.median()\n",
    "#                 temp_df['Hr_SD_NN'] = stdev(subj_treatment_aggregrated_df.Heart)\n",
    "#                 temp_df['Hr_SS_NN'] = sum_of_squares(subj_treatment_aggregrated_df.Heart)\n",
    "                \n",
    "#                 temp_df['Br_Mean_NN'] = subj_treatment_aggregrated_df.Breathing.mean()\n",
    "#                 temp_df['Br_Median_NN'] = subj_treatment_aggregrated_df.Breathing.median()\n",
    "#                 temp_df['Br_SD_NN'] = stdev(subj_treatment_aggregrated_df.Breathing)\n",
    "#                 temp_df['Br_SS_NN'] = sum_of_squares(subj_treatment_aggregrated_df.Breathing)\n",
    "# ###################################################################################################################\n",
    "\n",
    "                \n",
    "                # 'PP_Normalized', 'HR_Normalized', 'BR_Normalized'    \n",
    "                temp_df['PP_Mean'] = subj_treatment_aggregrated_df.PP_Normalized.mean()\n",
    "                temp_df['PP_Median'] = subj_treatment_aggregrated_df.PP_Normalized.median()\n",
    "                temp_df['PP_SD'] = stdev(subj_treatment_aggregrated_df.PP_Normalized)\n",
    "                temp_df['PP_SS'] = sum_of_squares(subj_treatment_aggregrated_df.PP_Normalized)\n",
    "\n",
    "                temp_df['Hr_Mean'] = subj_treatment_aggregrated_df.HR_Normalized.mean()\n",
    "                temp_df['Hr_Median'] = subj_treatment_aggregrated_df.HR_Normalized.median()\n",
    "                temp_df['Hr_SD'] = stdev(subj_treatment_aggregrated_df.HR_Normalized)\n",
    "                temp_df['Hr_SS'] = sum_of_squares(subj_treatment_aggregrated_df.HR_Normalized)\n",
    "                \n",
    "                temp_df['Br_Mean'] = subj_treatment_aggregrated_df.BR_Normalized.mean()\n",
    "                temp_df['Br_Median'] = subj_treatment_aggregrated_df.BR_Normalized.median()\n",
    "                temp_df['Br_SD'] = stdev(subj_treatment_aggregrated_df.BR_Normalized)\n",
    "                temp_df['Br_SS'] = sum_of_squares(subj_treatment_aggregrated_df.BR_Normalized)\n",
    "                \n",
    "                \n",
    "\n",
    "                aggregrated_df = aggregrated_df.append(temp_df)\n",
    "       \n",
    "      \n",
    "    aggregrated_df = pd.get_dummies(aggregrated_df, columns=['Gender'])\n",
    "    aggregrated_df = get_arousal_cols(aggregrated_df)\n",
    "    \n",
    "    return aggregrated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05661c4c-0cfd-4ee6-9bb1-bcc29dcab03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee440ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_window_aggregrated_df(single_sec_df, \n",
    "                                       train_window_size, \n",
    "                                       test_window_size, \n",
    "                                       rolling_window):\n",
    "    \n",
    "    total_window_size = train_window_size + test_window_size\n",
    "    next_idx = test_window_size if rolling_window else total_window_size\n",
    "    \n",
    "    aggregrated_df = pd.DataFrame()\n",
    "    print(single_sec_df.shape)\n",
    "    \n",
    "    for study in single_sec_df.Study_Name.unique():\n",
    "        \n",
    "        if study in all_study_combinations:\n",
    "            study_df = single_sec_df.copy()[single_sec_df.Study_Name == study]\n",
    "\n",
    "            for subj in study_df.Subject.unique():\n",
    "    #         for subj in study_df.Subject.unique()[:1]:\n",
    "\n",
    "                print(study, subj)\n",
    "                study_subj_df = study_df.copy()[study_df.Subject == subj]\n",
    "\n",
    "                for treatment in study_subj_df.Treatment.unique():\n",
    "                    treatment_df = study_subj_df.copy()[study_subj_df.Treatment == treatment]\n",
    "                    totalRows = treatment_df.shape[0]\n",
    "                    i = 0\n",
    "\n",
    "                    while i+total_window_size <= totalRows: # proceed for total_window_size rows\n",
    "                        treatment_agg_df = treatment_df.copy().iloc[i: i+train_window_size]\n",
    "                        label_agg_df = treatment_df.copy().iloc[i+train_window_size: i+total_window_size]\n",
    "\n",
    "                        # print(i, i+train_window_size, i+total_window_size)\n",
    "\n",
    "                        first_row = treatment_agg_df.iloc[0]\n",
    "                        i += next_idx\n",
    "\n",
    "                        temp_df = pd.DataFrame({\n",
    "                            'Study_Name': [first_row.Study_Name], \n",
    "                            'Subject': [first_row.Subject], \n",
    "                            'Study_Subject': [first_row.Study_Subject], \n",
    "                            'Treatment': [first_row.Treatment],\n",
    "                            'Gender': [first_row.Gender],\n",
    "                            'Age': [first_row.Age],\n",
    "                            'NASA_Effort': [first_row.NASA_Effort],\n",
    "                            'NASA_Frustration': [first_row.NASA_Frustration],\n",
    "                            'NASA_Mental': [first_row.NASA_Mental],\n",
    "                            'NASA_Performance': [first_row.NASA_Performance],\n",
    "                            'NASA_Physical': [first_row.NASA_Physical],\n",
    "                            'NASA_Temporal': [first_row.NASA_Temporal],\n",
    "                            'NASA_Total': [first_row.NASA_Total],\n",
    "                        })\n",
    "                        \n",
    "                        for col in ['Perinasal', 'Heart', 'Breathing']:\n",
    "#                             ###################################################################################################################\n",
    "#                             temp_df[col+'_Mean_NN'] = treatment_agg_df[col].mean()\n",
    "#                             temp_df[col+'_Median_NN'] = treatment_agg_df[col].median()\n",
    "#                             temp_df[col+'_SD_NN'] = stdev(treatment_agg_df[col])\n",
    "#                             temp_df[col+'_SS_NN'] = sum_of_squares(treatment_agg_df[col])\n",
    "                            \n",
    "#                             temp_df[col+'_Window_NN'] = ', '.join(str(v) for v in treatment_agg_df[col].values) \n",
    "#                             ###################################################################################################################\n",
    "\n",
    "                            \n",
    "                            \n",
    "                            ###################################################################################################################\n",
    "                            ### last_10_sec_df = treatment_agg_df.copy().tail(10)\n",
    "                            ### temp_df[col+'_Mean_10s'] = last_10_sec_df[col].mean()\n",
    "                            ### temp_df[col+'_Median_10s'] = last_10_sec_df[col].median()\n",
    "                            ### temp_df[col+'_SD_10s'] = stdev(last_10_sec_df[col])\n",
    "                            ### temp_df[col+'_SS_10s'] = sum_of_squares(last_10_sec_df[col])\n",
    "                            ###################################################################################################################\n",
    "\n",
    "\n",
    "                            \n",
    "                            ###################################################################################################################\n",
    "                            # if col=='Perinasal':\n",
    "                            #     norm_col='PP'\n",
    "                            # elif col=='Heart':\n",
    "                            #     norm_col='HR'\n",
    "                            # elif col=='Breathing':\n",
    "                            #     norm_col='BR'\n",
    "                                \n",
    "                            norm_col_dict = {\n",
    "                                'Perinasal': 'PP',\n",
    "                                'Heart': 'HR',\n",
    "                                'Breathing': 'BR',\n",
    "                            }    \n",
    "                            \n",
    "                            temp_df[col+'_Mean'] = treatment_agg_df[norm_col_dict[col]+'_Normalized'].mean()\n",
    "                            temp_df[col+'_Median'] = treatment_agg_df[norm_col_dict[col]+'_Normalized'].median()\n",
    "                            temp_df[col+'_SD'] = stdev(treatment_agg_df[norm_col_dict[col]+'_Normalized'])\n",
    "                            temp_df[col+'_SS'] = sum_of_squares(treatment_agg_df[norm_col_dict[col]+'_Normalized'])\n",
    "\n",
    "                            temp_df[col+'_Window'] = ', '.join(str(v) for v in treatment_agg_df[norm_col_dict[col]+'_Normalized'].values) \n",
    "                            ###################################################################################################################\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "                        ###########################################################################\n",
    "                        #                 This is for labeling\n",
    "                        ###########################################################################\n",
    "                        # temp_df['PP_Arousal_Mode'] = label_agg_df.PP_Arousal.mode()\n",
    "                        # temp_df['PP_2_Arousal_Mode'] = label_agg_df.PP_Arousal_2.mode()\n",
    "                        # temp_df['HR_Arousal_Mode'] = label_agg_df.HR_Arousal.mode()\n",
    "                        # temp_df['BR_Arousal_Mode'] = label_agg_df.BR_Arousal.mode()\n",
    "\n",
    "                        ###########################################################################\n",
    "                        # temp_df['PP_Arousal_Mode_Hist'] = label_agg_df.PP_Arousal.mode()\n",
    "                        # temp_df['HR_Arousal_Mode_Hist'] = label_agg_df.HR_Arousal.mode()\n",
    "                        # temp_df['BR_Arousal_Mode_Hist'] = label_agg_df.BR_Arousal.mode()\n",
    "\n",
    "                        temp_df['PP_Arousal_Mode_ecdf'] = label_agg_df.PP_Arousal_ecdf.mode()\n",
    "                        temp_df['HR_Arousal_Mode_ecdf'] = label_agg_df.HR_Arousal_ecdf.mode()\n",
    "                        temp_df['BR_Arousal_Mode_ecdf'] = label_agg_df.BR_Arousal_ecdf.mode()\n",
    "\n",
    "                        temp_df['PP_HR_Arousal_Mode_ecdf'] = label_agg_df.PP_HR_Arousal_ecdf.mode()\n",
    "                        temp_df['PP_BR_Arousal_Mode_ecdf'] = label_agg_df.PP_BR_Arousal_ecdf.mode()\n",
    "                        temp_df['HR_BR_Arousal_Mode_ecdf'] = label_agg_df.HR_BR_Arousal_ecdf.mode()\n",
    "                        temp_df['PP_HR_BR_Arousal_Mode_ecdf'] = label_agg_df.PP_HR_BR_Arousal_ecdf.mode()\n",
    "                        ###########################################################################\n",
    "\n",
    "\n",
    "                        aggregrated_df = aggregrated_df.append(temp_df)\n",
    "\n",
    "       \n",
    "    # print(aggregrated_df)\n",
    "    aggregrated_df = pd.get_dummies(aggregrated_df, columns=['Gender'])\n",
    "    aggregrated_df = rename_cols(aggregrated_df)\n",
    "    aggregrated_df = get_arousal_cols(aggregrated_df)  \n",
    "    # print(aggregrated_df)\n",
    "                    \n",
    "    print(aggregrated_df.shape)\n",
    "    # return get_post_processed_aggregrated_df(aggregrated_df)\n",
    "    return aggregrated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c7eabbd-c980-48bf-b755-6119ed2cb518",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                    # temp_df = pd.DataFrame({\n",
    "                    #     'Study_Name': [first_row.Study_Name], \n",
    "                    #     'Subject': [first_row.Subject], \n",
    "                    #     'Study_Subject': [first_row.Study_Subject], \n",
    "                    #     'Treatment': [first_row.Treatment],\n",
    "                    #     'Gender': [first_row.Gender],\n",
    "                    #     'Age': [first_row.Age],\n",
    "                    #     'NASA_Effort': [first_row.NASA_Effort],\n",
    "                    #     'NASA_Frustration': [first_row.NASA_Frustration],\n",
    "                    #     'NASA_Mental': [first_row.NASA_Mental],\n",
    "                    #     'NASA_Performance': [first_row.NASA_Performance],\n",
    "                    #     'NASA_Physical': [first_row.NASA_Physical],\n",
    "                    #     'NASA_Temporal': [first_row.NASA_Temporal],\n",
    "                    #     'NASA_Total': [first_row.NASA_Total],\n",
    "                    # })\n",
    "        \n",
    "                        \n",
    "        \n",
    "        \n",
    "        \n",
    "#                     temp_df['PP_Mean'] = treatment_agg_df.Perinasal_Log.mean()\n",
    "#                     temp_df['PP_Median'] = treatment_agg_df.Perinasal_Log.median()\n",
    "#                     temp_df['PP_SD'] = stdev(treatment_agg_df.Perinasal_Log)\n",
    "#                     temp_df['PP_SS'] = sum_of_squares(treatment_agg_df.Perinasal_Log)\n",
    "\n",
    "#                     temp_df['HR_Mean'] = treatment_agg_df.Heart.mean()\n",
    "#                     temp_df['HR_Median'] = treatment_agg_df.Heart.median()\n",
    "#                     temp_df['HR_SD'] = stdev(treatment_agg_df.Heart)\n",
    "#                     temp_df['HR_SS'] = sum_of_squares(treatment_agg_df.Heart)\n",
    "\n",
    "#                     temp_df['BR_Mean'] = treatment_agg_df.Breathing.mean()\n",
    "#                     temp_df['BR_Median'] = treatment_agg_df.Breathing.median()\n",
    "#                     temp_df['BR_SD'] = stdev(treatment_agg_df.Breathing)\n",
    "#                     temp_df['BR_SS'] = sum_of_squares(treatment_agg_df.Breathing)\n",
    "    \n",
    "                    \n",
    "                    \n",
    "#                     for col in ['Perinasal_Log', 'Heart', 'Breathing']:\n",
    "#                         # temp_df[col+'_Window'] = [treatment_agg_df[col].values]\n",
    "#                         temp_df[col+'_Window'] = ', '.join(str(v) for v in treatment_agg_df[col].values)  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc0a1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_name_with_window_info(file_name, \n",
    "                                        train_window_size, \n",
    "                                        test_window_size, \n",
    "                                        rolling):\n",
    "    \n",
    "    final_file_name = file_name[:-4]\n",
    "    if rolling: final_file_name+='_rolling'\n",
    "    \n",
    "    return final_file_name+'_w'+str(train_window_size)+'_'+str(test_window_size)+'.csv'\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c36a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af697c-f4f2-4101-8b8f-ce90842f8aff",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffbb115-19ef-4cc8-9263-058d718ae64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features_static = model_features.copy()\n",
    "# model_features_static += ['PP_Mean_10s',\n",
    "#                           'PP_SD_10s',\n",
    "#                           'Heart_Mean_10s',\n",
    "#                           'Heart_SD_10s',\n",
    "#                           'Breathing_Mean_10s',\n",
    "#                           'Breathing_SD_10s']\n",
    "\n",
    "model_features_ts = ['Perinasal_Window', 'Heart_Window', 'Breathing_Window']\n",
    "\n",
    "dnn_features = model_features_static + model_features_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c8a29-ad36-4a11-9ac5-acab2019b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ts_features(df):\n",
    "    for model_feature_ts in model_features_ts:\n",
    "        df[model_feature_ts] = df[model_feature_ts].apply(lambda x: np.array(x.split(', ')).astype('float64'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_categorical_labels(df):\n",
    "    for arousal_signal in arousal_signals:\n",
    "        label = arousal_signal + '_Arousal_Mode'\n",
    "        label_cat = label + '_Cat'\n",
    "        \n",
    "        df[label_cat] = df[label].replace(['relaxed','stressed', 'neutral'],\n",
    "                                          [0, 1, -1])\n",
    "\n",
    "        # df[label_cat] = np.where(df[label] == 'relaxed', 0, 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def split_static_and_ts_features_as_matrix(df):\n",
    "    return df[model_features_static].values, np.array(df[model_features_ts].values.tolist())\n",
    "\n",
    "def model_input_data(X):\n",
    "    X_static, X_ts = split_static_and_ts_features_as_matrix(X)\n",
    "    return [np.asarray(X_ts).astype('float32'), np.asarray(X_static).astype('float32')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be21e9c1-c52d-4fc4-847a-a79d4843779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "# def auc_m(y_true, y_pred):\n",
    "#     return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda055f-948d-41d8-931a-b51d25b31721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnn_model():\n",
    "    if model_name == 'LSTM':\n",
    "        return get_lstm_model()\n",
    "    # elif model_name == 'DNN':\n",
    "    #     return get_dnn_v1_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972b53c-4242-4a15-98c2-2531ec52de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal loss\n",
    "def focal_loss_custom(alpha, gamma):\n",
    "    def binary_focal_loss(y_true, y_pred):\n",
    "        fl = tf_a.losses.SigmoidFocalCrossEntropy(alpha=alpha, gamma=gamma)\n",
    "        y_true_K = tf.ones_like(y_true)\n",
    "        focal_loss = fl(y_true, y_pred)\n",
    "        return focal_loss\n",
    "    return binary_focal_loss\n",
    "\n",
    "def get_compiled_model(model):\n",
    "        # binary cross entropy loss\n",
    "        # model.compile(loss='binary_crossentropy', \n",
    "        #               optimizer='adam', \n",
    "        #               metrics=['accuracy', f1_m, precision_m, recall_m])\n",
    "    \n",
    "    \n",
    "        # model.compile(loss=focal_loss_custom(alpha=0.2, gamma=2.0), optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "        model.compile(loss=focal_loss_custom(alpha=0.2, gamma=2.0), \n",
    "                      optimizer='adam', \n",
    "                      metrics=[\n",
    "                          'accuracy',\n",
    "\n",
    "                          keras.metrics.AUC(),\n",
    "\n",
    "                          f1_m,\n",
    "                          precision_m,\n",
    "                          recall_m,\n",
    "\n",
    "                           # keras.metrics.AUC(),\n",
    "                           # keras.metrics.Precision(),\n",
    "                           # keras.metrics.Recall()\n",
    "                      ])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7df214d-a809-42ae-8963-cace0f611297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model():\n",
    "    # Define timesteps and the number of features\n",
    "    n_timesteps = 3\n",
    "    n_features = int(dnn_window_size[:2])\n",
    "    n_static_features = len(model_features_static)  ## X_train_static.shape[1] = 13\n",
    "    n_outputs = 1\n",
    "\n",
    "    # RNN + SLP Model\n",
    "    # Define input layer\n",
    "    recurrent_input = Input(shape=(n_timesteps, n_features),name='TIMESERIES_INPUT')\n",
    "    static_input = Input(shape=(n_static_features, ),name='STATIC_INPUT') \n",
    "\n",
    "    #CNN Layers\n",
    "\n",
    "    conv_layer_one = Conv1D(filters=32, kernel_size=8, strides=1, activation='relu', padding='same')(recurrent_input)\n",
    "    pool_layer_one = MaxPooling1D(pool_size = 2, name ='POOLING_LAYER_1')(conv_layer_one)\n",
    "\n",
    "    conv_layer_two = Conv1D(filters=16, kernel_size=4, strides=1, activation='relu', padding='same')(pool_layer_one)\n",
    "    pool_layer_two = MaxPooling1D(pool_size = 1, name ='POOLING_LAYER_2')(conv_layer_two)\n",
    "\n",
    "    # RNN Layers\n",
    "    # layer - 1\n",
    "    rec_layer_one = Bidirectional(LSTM(128, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01),return_sequences=True),name ='BIDIRECTIONAL_LAYER_1')(pool_layer_two)\n",
    "    rec_layer_one = Dropout(0.1,name ='DROPOUT_LAYER_1')(rec_layer_one)\n",
    "\n",
    "    # layer - 2\n",
    "    rec_layer_two = Bidirectional(LSTM(64, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)),name ='BIDIRECTIONAL_LAYER_2')(rec_layer_one)\n",
    "    rec_layer_two = Dropout(0.1, name ='DROPOUT_LAYER_2')(rec_layer_two)\n",
    "\n",
    "    # SLP Layers\n",
    "    static_layer_one = Dense(64, kernel_regularizer=l2(0.001), activation='relu', name='DENSE_LAYER_1')(static_input)\n",
    "\n",
    "    # Combine layers - RNN + SLP\n",
    "    combined = Concatenate(axis= 1,name = 'CONCATENATED_TIMESERIES_STATIC')([rec_layer_two,static_layer_one])\n",
    "\n",
    "    # flatten_layer = Flatten()(combined)\n",
    "\n",
    "    combined_dense_two = Dense(64, activation='relu',name='DENSE_LAYER_2')(combined)\n",
    "    combined_dense_three = Dense(32, activation='relu',name='DENSE_LAYER_3')(combined_dense_two)\n",
    "    output = Dense(n_outputs, activation='sigmoid', name='OUTPUT_LAYER')(combined_dense_three)\n",
    "    # output = Dense(n_outputs, activation='softmax', name='OUTPUT_LAYER')(combined_dense_three)\n",
    "\n",
    "    # Compile ModeL\n",
    "    model = Model(inputs=[recurrent_input, static_input], outputs=[output])\n",
    "    model = get_compiled_model(model)\n",
    "    # model.summary()\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef9c8fb-818d-4a27-bf41-ac52e9bad3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnn_model_and_metrics(df, arousal_signal, k_fold=False):\n",
    "    \n",
    "    #####################################################################################\n",
    "    # arousal_col = arousal_signal + '_Arousal_Mode_Cat'\n",
    "    df['Arousal_Mode'] = df[arousal_signal + '_Arousal_Mode_Cat']\n",
    "    #####################################################################################\n",
    "\n",
    "    \n",
    "    X_all = df.copy()[dnn_features]\n",
    "    y_all = df.copy()['Arousal_Mode']\n",
    "    \n",
    "    # print(y_all.to_string())\n",
    "    # print(y_all.unique())\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    dnn_model_name = add_path(add_path(all_studies_data_dir, models_dir), dnn_window_size)+'lstm_'+arousal_signal+'_'+study_combination\n",
    "    if os.path.exists(dnn_model_name+'.json'):\n",
    "        # -------------------------------------------\n",
    "        # Load from the saved model and weights\n",
    "        # -------------------------------------------\n",
    "        print('Loading from saved model and weights.....')\n",
    "        json_file = open(dnn_model_name+'.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "    \n",
    "        model = model_from_json(loaded_model_json)\n",
    "        model.load_weights(dnn_model_name+'.h5')\n",
    "        model = get_compiled_model(model)\n",
    "        \n",
    "    else:\n",
    "        cur_epochs = 1 if k_fold else epochs\n",
    "        model = get_dnn_model()\n",
    "        \n",
    "        history =  model.fit(model_input_data(X_train),\n",
    "                         y_train, \n",
    "                         epochs=cur_epochs, \n",
    "                         batch_size=batch_size, \n",
    "                         verbose=verbose,\n",
    "                         validation_data=(model_input_data(X_valid), y_valid)\n",
    "                        )\n",
    "        \n",
    "        # -------------------------------------------\n",
    "        # Download the model and weights\n",
    "        # -------------------------------------------\n",
    "        model_json = model.to_json()\n",
    "        with open(dnn_model_name+'.json', 'w') as json_file:\n",
    "            json_file.write(model_json)\n",
    "        model.save_weights(dnn_model_name+'.h5')\n",
    "    \n",
    "    \n",
    "    ######################################################################\n",
    "    loss, accuracy, auc, f1_score, precision, recall = model.evaluate(model_input_data(X_valid), y_valid, verbose=0)\n",
    "    ######################################################################\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ######################################################################\n",
    "    y_prob = model.predict(model_input_data(X_valid))\n",
    "    y_pred = np.where(y_prob > prediction_threshold, 1, 0).flatten().tolist()\n",
    "    \n",
    "    Accuracy, AUC, F1, Recall, Precision, Specificity = get_metrics(model, X_valid, y_valid, y_pred, y_prob.flatten().tolist())\n",
    "    \n",
    "    \n",
    "    print('\\n------------------------ Train Study ------------------------') \n",
    "    print('Train Data - True --> ')\n",
    "    print(collections.Counter(df[arousal_signal + '_Arousal_Mode_Cat']))\n",
    "\n",
    "    print('\\nValidation Data - True --> ')\n",
    "    print(collections.Counter(y_valid))\n",
    "    \n",
    "    print('\\nValidation Data - Prediction --> ')\n",
    "    print(collections.Counter(y_pred))\n",
    "    ######################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return model, {'loss': loss,\n",
    "                   \n",
    "                   'accuracy': accuracy,\n",
    "                   'auc': auc,\n",
    "                   'f1_score': f1_score, \n",
    "                   'precision': precision, \n",
    "                   'recall': recall,\n",
    "                   \n",
    "                   'Accuracy': Accuracy, \n",
    "                   'AUC': AUC,\n",
    "                   'F1': F1, \n",
    "                   'Precision': Precision, \n",
    "                   'Recall': Recall,\n",
    "                   'Specificity': Specificity,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba56d70-abaf-4039-8a61-e27738670075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dnn_model(df, model_features, arousal_signal, model_train_method, study_subjects=None):\n",
    "\n",
    "    \n",
    "    # #####################################################################################\n",
    "    # # arousal_col = arousal_signal + '_Arousal_Mode_Cat'\n",
    "    # df['Arousal_Mode'] = df[arousal_signal + '_Arousal_Mode_Cat']\n",
    "    # #####################################################################################\n",
    "\n",
    "    train_df = df.copy()[df.Study_Subject.isin(study_subjects)]\n",
    "    \n",
    "    #####################################################################################\n",
    "    #                               MODELING\n",
    "    #####################################################################################\n",
    "    model, metrics = get_dnn_model_and_metrics(train_df, arousal_signal, k_fold=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    model_metrics[arousal_signal]['K_Fold']['Accuracy'].append(metrics['Accuracy'])\n",
    "    model_metrics[arousal_signal]['K_Fold']['F1'].append(metrics['F1'])\n",
    "    model_metrics[arousal_signal]['K_Fold']['Recall'].append(metrics['Recall'])\n",
    "    model_metrics[arousal_signal]['K_Fold']['Precision'].append(metrics['Precision'])\n",
    "    model_metrics[arousal_signal]['K_Fold']['AUC'] = metrics['AUC']\n",
    "    model_metrics[arousal_signal]['K_Fold']['Specificity'] = metrics['Specificity']\n",
    "    #####################################################################################\n",
    "    \n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995c31f-1692-4a69-9125-a58cf20c885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_dnn_model(df, arousal_signal):\n",
    "    \n",
    "    # print('----------------------------------------> Train Studies: ' + str(df.Study_Name.unique()))\n",
    "    \n",
    "    #############################################################\n",
    "    #                       K-Fold Models\n",
    "    #############################################################\n",
    "    if run_k_fold:\n",
    "        study_subjects = np.array(df.Study_Subject.unique())\n",
    "        # print(study_subjects)\n",
    "        for i, indices in enumerate(KFold(n_splits=k_fold_n_splits).split(study_subjects)):\n",
    "            print('Running ' + str(k_fold_n_splits) + '-fold iteration: ' + str(i+1) + '\\n')\n",
    "            # print(study_subjects[indices[1]])\n",
    "            train_dnn_model(df, model_features, arousal_signal, model_train_method, study_subjects[indices[1]])\n",
    "            # print(model_metrics)\n",
    "\n",
    "        print_metrics(model_metrics)    \n",
    "    #############################################################    \n",
    "        \n",
    "        \n",
    "        \n",
    "    #############################################################\n",
    "    #          Final Model to Run on Test Study    \n",
    "    #############################################################    \n",
    "    model, metrics = get_dnn_model_and_metrics(df, arousal_signal)\n",
    "\n",
    "    model_metrics[arousal_signal]['Train']['Accuracy'] = metrics['Accuracy']\n",
    "    model_metrics[arousal_signal]['Train']['AUC'] = metrics['AUC']\n",
    "    model_metrics[arousal_signal]['Train']['F1'] = metrics['F1']\n",
    "    model_metrics[arousal_signal]['Train']['Precision'] = metrics['Precision']\n",
    "    model_metrics[arousal_signal]['Train']['Recall'] = metrics['Recall']\n",
    "    model_metrics[arousal_signal]['Train']['Specificity'] = metrics['Specificity']\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_dnn_model(model, test_study, test_df, arousal_signal):\n",
    "    test_df['Arousal_Mode'] = test_df[arousal_signal + '_Arousal_Mode_Cat']\n",
    "    \n",
    "    X_test = test_df[dnn_features]\n",
    "    y_test = test_df['Arousal_Mode']\n",
    "    \n",
    "    \n",
    "    ######################################################################\n",
    "    loss, accuracy, auc, f1_score, precision, recall = model.evaluate(model_input_data(X_test), y_test, verbose=0)\n",
    "    ######################################################################\n",
    "    \n",
    "    \n",
    "    ######################################################################\n",
    "    y_prob = model.predict(model_input_data(X_test))\n",
    "    y_pred = np.where(y_prob > prediction_threshold, 1,0).flatten().tolist()\n",
    "    \n",
    "    Accuracy, AUC, F1, Recall, Precision, Specificity = get_metrics(model, X_test, y_test, y_pred, y_prob.flatten().tolist())\n",
    "    \n",
    "    print('Test Data - True --> ')\n",
    "    print(collections.Counter(y_test))\n",
    "    \n",
    "    print('\\nTest Data - Prediction --> ')\n",
    "    print(collections.Counter(y_pred))\n",
    "    ######################################################################\n",
    "    \n",
    "    \n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Accuracy'] = Accuracy\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['AUC'] = AUC\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['F1'] = F1\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Recall'] = Recall\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Precision'] = Precision\n",
    "    model_metrics[arousal_signal]['Test'][test_study.upper()]['Specificity'] = Specificity\n",
    "    \n",
    "    # if print_all: print('Accuracy: %.2f \\nAUC: %.2f \\nF1: %.2f \\nRecall: %.2f \\nPrecision: %.2f \\nSpecificity: %.2f\\n' % (accuracy, auc, f1_score, recall, precision, specificity))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
