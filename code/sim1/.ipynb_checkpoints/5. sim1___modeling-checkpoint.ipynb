{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from statistics import mean, stdev\n",
    "from scipy.stats import mode\n",
    "\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, plot_roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "def reset_plt():\n",
    "    plt.figure().clear()\n",
    "    plt.close()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    \n",
    "    sns.set_context(\"paper\", rc={\"font.size\": 16,\n",
    "                                 \"axes.titlesize\": 24,\n",
    "                                 \"axes.labelsize\": 16}) \n",
    "\n",
    "\n",
    "data_path = '../../data/sim1/'\n",
    "figure_path = '../../figure/sim1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.read_csv(data_path + \"data_3.csv\")\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.Subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df.Subject.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round(num, point=2):\n",
    "    return round(num, point)\n",
    "\n",
    "def get_rounded_str(num, point):\n",
    "    return str(get_round(num, point))\n",
    "\n",
    "\n",
    "def get_drive_name(drive):\n",
    "    if drive == 2:\n",
    "        return 'CD'\n",
    "    elif drive == 3:\n",
    "        return 'MD'\n",
    "    elif drive == 4:\n",
    "        return 'ED'\n",
    "    elif drive == 5:\n",
    "        return 'FD'\n",
    "\n",
    "\n",
    "def get_test_subjs(arousal_signal):\n",
    "    \n",
    "    ######################################\n",
    "    # 'PP', 'PP_2', 'HR', 'BR', 'PP_HR_BR'\n",
    "    ######################################\n",
    "    \n",
    "    if arousal_signal == 'PP':\n",
    "        #####################################\n",
    "        # return [2, 31, 66, 47, 44, 25, 24]\n",
    "        #####################################\n",
    "        return [18, 23, 16, 25, 8, 45, 2]\n",
    "    \n",
    "    elif arousal_signal == 'PP_2':\n",
    "        return [44, 20, 16, 68, 33, 60, 18]\n",
    "    \n",
    "    elif arousal_signal == 'HR':\n",
    "        return [61, 29, 24, 38, 84, 2, 17]\n",
    "    \n",
    "    elif arousal_signal == 'BR':\n",
    "        return [44, 62, 81, 20, 61, 38, 79]\n",
    "    \n",
    "    elif arousal_signal == 'PP_HR_BR':\n",
    "        return [31, 66, 16, 29, 62, 44, 36]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_splitted_data(final_df, model_features, arousal_signal, predict_col, model_train_method, subjects_test=None):\n",
    "    \n",
    "    unique_subjs = final_df.Subject.unique()\n",
    "    \n",
    "    df_arousal_count = final_df.groupby(['Arousal_Mode']).agg({'Arousal_Mode': 'count'})\n",
    "    df_arousal_count = df_arousal_count.apply(lambda x: 100 * x / float(x.sum()))\n",
    "    # print(df_arousal_count.head(2))\n",
    "\n",
    "    ########################################################################\n",
    "    '''\n",
    "    train_subj_end = 65\n",
    "\n",
    "    train_df = final_df[final_df.Subject < train_subj_end]\n",
    "    test_df = final_df[final_df.Subject >= train_subj_end]\n",
    "    \n",
    "    train_subjs = train_df.Subject.unique()\n",
    "    test_subjs = test_df.Subject.unique()\n",
    "    \n",
    "    print('\\n\\nTest Subjects -->\\n', test_subjs)\n",
    "    '''\n",
    "    ########################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################################################################\n",
    "    # '''\n",
    "    if model_train_method=='best_accurate':\n",
    "        test_subjs = get_test_subjs(arousal_signal)\n",
    "    elif model_train_method=='bootstrap':\n",
    "        test_subjs = random.sample(list(final_df.Subject.unique()), 7)\n",
    "    elif model_train_method=='kfold':\n",
    "        test_subjs = subjects_test\n",
    "        \n",
    "    train_subjs = [subj for subj in unique_subjs if subj not in test_subjs]\n",
    "    \n",
    "    train_df = final_df[final_df.Subject.isin(train_subjs)]\n",
    "    test_df = final_df[final_df.Subject.isin(test_subjs)]\n",
    "    \n",
    "    print('\\n\\nTest Subjects -->\\n', test_subjs)\n",
    "    # '''\n",
    "    ########################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('\\n\\nTotal Train Subjects: ' + str(len(train_subjs)) + '    Percentage: ' + str(round(100*len(train_subjs)/len(unique_subjs), 2)) + '%')\n",
    "    print('Total Test Subjects: ' + str(len(test_subjs)) + '    Percentage: ' + str(round(100*len(test_subjs)/len(unique_subjs), 2)) + '%' + '\\n\\n')\n",
    "\n",
    "\n",
    "    train_df_arousal_count = train_df.groupby(['Arousal_Mode']).agg({'Arousal_Mode': 'count'})\n",
    "    train_df_arousal_count = train_df_arousal_count.apply(lambda x: 100 * x / float(x.sum()))\n",
    "    print('Train Data Percentage -->')\n",
    "    print(train_df_arousal_count)\n",
    "\n",
    "\n",
    "    test_df_arousal_count = test_df.groupby(['Arousal_Mode']).agg({'Arousal_Mode': 'count'})\n",
    "    test_df_arousal_count = test_df_arousal_count.apply(lambda x: 100 * x / float(x.sum()))\n",
    "    print('\\nTest Data Percentage -->')\n",
    "    print(test_df_arousal_count)\n",
    "\n",
    "\n",
    "    print('\\n\\nTotal Train Rows: ' + str(len(train_df)) + '    Percentage: ' + str(round(100*len(train_df)/len(final_df), 2)) + '%')\n",
    "    print('Total Test Rows: ' + str(len(test_df)) + '    Percentage: ' + str(round(100*len(test_df)/len(final_df), 2)) + '%' + '\\n\\n')\n",
    "\n",
    "    \n",
    "    X_train = train_df[model_features]\n",
    "    y_train = train_df[[predict_col]]\n",
    "\n",
    "    X_test = test_df[model_features]\n",
    "    y_test = test_df[[predict_col]]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = final_df.copy().rename(columns={\n",
    "                             'Gender_Female': 'Gender', \n",
    "                             'Effort': 'NASA_Effort',\n",
    "                             'Frustration': 'NASA_Frustration', \n",
    "                             'Mental_Demand': 'NASA_Mental',\n",
    "                             'Performance': 'NASA_Performance', \n",
    "                             'Physical_Demand': 'NASA_Physical',\n",
    "                             'Temporal_Demand': 'NASA_Temporal', \n",
    "                             'NASA_Total_Sum': 'NASA_Total',\n",
    "                             'Hr_Mean': 'HR_Mean',\n",
    "                             'Hr_SD': 'HR_SD',\n",
    "                             'Hr_Median': 'HR_Median',\n",
    "                             'Hr_SS': 'HR_SS',\n",
    "                             'Br_Mean': 'BR_Mean',\n",
    "                             'Br_SD': 'BR_SD',\n",
    "                             'Br_Median': 'BR_Median',\n",
    "                             'Br_SS': 'BR_SS'\n",
    "                            })\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# model_all_features = [\n",
    "#     'Age', 'Gender',     \n",
    "#     'NASA_Mental', 'NASA_Physical', 'NASA_Effort', 'NASA_Frustration', 'NASA_Temporal', 'NASA_Performance', 'NASA_Total',          \n",
    "#     'Perinasal_Mean', 'Perinasal_Median', 'Perinasal_SD', 'Perinasal_SS',     \n",
    "#     'HR_Mean', 'HR_Median', 'HR_SD', 'HR_SS',\n",
    "#     'BR_Mean', 'BR_Median', 'BR_SD', 'BR_SS'\n",
    "# ]\n",
    "################################################################################################\n",
    "\n",
    "model_features = [\n",
    "    'Age', 'Gender',     \n",
    "    'NASA_Physical', 'NASA_Effort', 'NASA_Frustration', 'NASA_Temporal', 'NASA_Performance',          \n",
    "    'Perinasal_Mean', 'Perinasal_SD',     \n",
    "    'HR_Mean', 'HR_SD',\n",
    "    'BR_Mean', 'BR_SD'\n",
    "]\n",
    "\n",
    "# print(len(model_features), len(plot_features)) ## 22, 21\n",
    "# print(plot_features)\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# model_features = [\n",
    "#     'Age', 'Gender_Female', 'Gender_Male', \n",
    "#     'Effort', 'Frustration', 'Mental_Demand', 'Performance', 'Physical_Demand', 'Temporal_Demand', 'NASA_Total_Sum', \n",
    "#     'Perinasal_Mean', 'Perinasal_SD', 'Perinasal_Median', 'Perinasal_SS', \n",
    "#     'Hr_Mean', 'Hr_SD', 'Hr_Median', 'Hr_SS', \n",
    "#     'Br_Mean', 'Br_SD', 'Br_Median', 'Br_SS',\n",
    "\n",
    "\n",
    "# ################################################################################################\n",
    "# #              Not Available in any of SIM2, TT1, EmailStress Studies\n",
    "# ################################################################################################\n",
    "# #     'STAI', 'Type_AB', \n",
    "# #     'NASA_Total_Sum_Normalized', \n",
    "# #     'Effort_Normalized', 'Frustration_Normalized', 'Mental_Demand_Normalized',\n",
    "# #     'Performance_Normalized', 'Physical_Demand_Normalized', 'Temporal_Demand_Normalized', \n",
    "# #     'Palm_Mean', 'Palm_SD', 'Palm_Median', 'Palm_SS', \n",
    "# #     'Drive_Label_CD', 'Drive_Label_ED', 'Drive_Label_MD', \n",
    "# #     'Nasa_Cluster_High', 'Nasa_Cluster_Low',\n",
    "# ################################################################################################\n",
    "\n",
    "# ]\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "model = RandomForestClassifier(n_estimators = 200,\n",
    "                               max_features = 'auto',\n",
    "                               bootstrap = True)\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(arousal_signal, model_df, test_df, y_test, y_pred, do_normalize):\n",
    "    \n",
    "    #####################################################################################\n",
    "    reset_plt()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    #-------------------------------------------------------------#\n",
    "    # labels = [\"normal\", \"relaxed\", \"stressed\", \"unknown\"]\n",
    "    # labels = [\"relaxed\", \"normal\", \"unknown\", \"stressed\"]\n",
    "    # labels = [\"relaxed\", \"stressed\"]\n",
    "    labels = sorted(model_df.Arousal_Mode.unique())\n",
    "    #-------------------------------------------------------------#\n",
    "    \n",
    "    if do_normalize:\n",
    "        conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=labels, normalize='all'))\n",
    "        sns.heatmap(conf_mat*100, annot=True, annot_kws={\"size\": 24})\n",
    "        # plt.title('Confusion Matrix - ' + arousal_signal + ' %', fontsize=40)\n",
    "        plot_name = arousal_signal.lower() + '_percentage'\n",
    "        \n",
    "    else:\n",
    "        conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=labels))\n",
    "        # annot = [str(val)+\"%\" for val in conf_mat]\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', annot_kws={\"size\": 24})\n",
    "        # plt.title('Confusion Matrix - ' + arousal_signal, fontsize=40)\n",
    "        plot_name = arousal_signal.lower() \n",
    "\n",
    "    ax.collections[0].colorbar.ax.tick_params(labelsize=28)\n",
    "    \n",
    "    ax.set_title('%')\n",
    "    \n",
    "    ax.set_xticklabels(labels, fontsize=24)\n",
    "    ax.set_yticklabels(labels, fontsize=24)\n",
    "    \n",
    "    ax.set_xlabel('Predicted', fontsize=32)\n",
    "    ax.set_ylabel('Actual', fontsize=32)\n",
    "\n",
    "    plt.savefig(figure_path + plot_name + '_confusion_matrix.png')\n",
    "    plt.savefig(figure_path + plot_name + '_confusion_matrix.pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "\n",
    "def get_all_confusion_matrices(arousal_signal, model_df, test_df, y_test, y_pred):\n",
    "    \n",
    "    get_confusion_matrix(arousal_signal, model_df, test_df, y_test, y_pred, do_normalize=False)\n",
    "    get_confusion_matrix(arousal_signal, model_df, test_df, y_test, y_pred, do_normalize=True)\n",
    "\n",
    "    #####################################################################################\n",
    "    # print('\\n\\nConfusion Matrix:')\n",
    "    # print(pd.DataFrame(confusion_matrix(y_test, y_pred, labels=labels)))\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    labels = sorted(model_df.Arousal_Mode.unique())\n",
    "    \n",
    "    reset_plt()\n",
    "    fig, axs = plt.subplots(3, figsize = (12, 36))\n",
    "    fig.suptitle(arousal_signal)\n",
    "\n",
    "    for i, drive in enumerate(test_df.Drive.unique()):\n",
    "        drive_test_df = test_df.copy()[test_df.Drive == drive]\n",
    "        y_test_drive = drive_test_df.Arousal_Mode\n",
    "        y_pred_drive = drive_test_df.Prediction\n",
    "\n",
    "        conf_mat = pd.DataFrame(confusion_matrix(y_test_drive, y_pred_drive, labels = labels))\n",
    "        axis = axs[i]\n",
    "\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', annot_kws={\"size\": 24}, ax = axis)\n",
    "        axis.collections[0].colorbar.ax.tick_params(labelsize=32)\n",
    "        \n",
    "        axis.title.set_text(get_drive_name(drive))\n",
    "        axis.set_xticklabels(labels, fontsize=24)\n",
    "        axis.set_yticklabels(labels, fontsize=24)\n",
    "        axis.set_xlabel('Predicted', fontsize=24)\n",
    "        axis.set_ylabel('Actual', fontsize=24)\n",
    "\n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_drive_confusion_matrix.png')\n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_drive_confusion_matrix.pdf')\n",
    "    \n",
    "    # plt.show()\n",
    "    #####################################################################################\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_feature_importance(model, X_train, arousal_signal):\n",
    "    \n",
    "    df_feature_importance = pd.DataFrame(model.feature_importances_, \n",
    "                                     index=X_train.columns, \n",
    "                                     columns=['feature importance']).sort_values('feature importance', ascending=False)\n",
    "    feature_imp = pd.Series(model.feature_importances_,\n",
    "                            index=X_train.columns).sort_values(ascending=False).round(2)\n",
    "\n",
    "    reset_plt()\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    \n",
    "    sns_plt = sns.barplot(x=feature_imp, y=feature_imp.index) \n",
    "    \n",
    "    # plt.title(arousal_signal + ' - Important Features', fontsize=36)\n",
    "    # sns_plt.axes.set_title(arousal_signal + ' - Important Features', fontsize=36)\n",
    "    \n",
    "    sns_plt.set_xlabel('Feature Importance Score', fontsize=36)\n",
    "    sns_plt.set_ylabel('Features', fontsize=36)\n",
    "\n",
    "    sns_plt.tick_params(labelsize=24)\n",
    "#     sns_plt.set_xticklabels(sns_plt.get_xticklabels(), fontsize = 24)\n",
    "    sns_plt.set_yticklabels(sns_plt.get_yticklabels(), fontsize = 24, rotation = 30)\n",
    "\n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_feature_importance.png')\n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_feature_importance.pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def get_correlation_plot(model_df, arousal_signal, selected_model_features):\n",
    "    cor_df = model_df.copy()[['Arousal_Mode'] + selected_model_features]\n",
    "    corr = cor_df.corr().round(3)\n",
    "\n",
    "    reset_plt()\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    \n",
    "    sns_plt = sns.heatmap(corr, cmap=\"YlGnBu\", center=0, square=True, linewidths=.5, annot=True, annot_kws={\"size\": 24})\n",
    "    sns_plt.collections[0].colorbar.ax.tick_params(labelsize=32)\n",
    "\n",
    "    sns_plt.set_xticklabels(sns_plt.get_yticklabels(), rotation = 45, fontsize = 38)\n",
    "    sns_plt.set_yticklabels(sns_plt.get_yticklabels(), rotation = 0, fontsize = 38) \n",
    "    \n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_correlation_plot.png')\n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_correlation_plot.pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_bootstrap_results(model_df, model_features, arousal_signal, model_train_method, subjects_test=None):\n",
    "\n",
    "    #####################################################################################\n",
    "    arousal_col = arousal_signal + '_Arousal_Mode'\n",
    "\n",
    "    # 'PP_Arousal_Mode', 'HR_Arousal_Mode', 'BR_Arousal_Mode'\n",
    "    # 'PP_HR_Arousal_Mode', 'HR_BR_Arousal_Mode', 'PP_HR_BR_Arousal_Mode'\n",
    "    #####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################\n",
    "    model_df['Arousal_Mode'] = model_df[arousal_col]\n",
    "    # print(model_df.Arousal_Mode.unique())\n",
    "    #####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################\n",
    "    #                               MODELING\n",
    "    #####################################################################################\n",
    "    X_train, y_train, X_test, y_test, train_df, test_df = get_splitted_data(model_df, \n",
    "                                                                            model_features,\n",
    "                                                                            arousal_signal,\n",
    "                                                                            'Arousal_Mode',\n",
    "                                                                            model_train_method,\n",
    "                                                                            subjects_test) \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_df['Prediction'] = y_pred\n",
    "\n",
    "    Accuracy = get_round(accuracy_score(y_test, y_pred))\n",
    "    F1 = get_round(f1_score(y_test, y_pred, average='weighted'))\n",
    "    Recall = get_round(recall_score(y_test, y_pred, average='weighted'))\n",
    "    Precision = get_round(precision_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    # Ref: https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n",
    "    AUC = get_round(roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    Specificity = get_round(tn / (tn+fp))\n",
    "    \n",
    "    print('Accuracy:' + str(Accuracy))\n",
    "    print('AUC: ' + str(AUC))\n",
    "    print('F1: ' + str(F1))\n",
    "    print('Recall: ' + str(Recall))\n",
    "    print('Precision: ' + str(Precision))\n",
    "    print('Specificity: ' + str(Specificity))\n",
    "    print('\\n\\n')  \n",
    "    \n",
    "    signal_metrics[arousal_signal]['Accuracy'].append(Accuracy)\n",
    "    signal_metrics[arousal_signal]['AUC'].append(AUC)\n",
    "    signal_metrics[arousal_signal]['F1'].append(F1)\n",
    "    signal_metrics[arousal_signal]['Recall'].append(Recall)\n",
    "    signal_metrics[arousal_signal]['Precision'].append(Precision)\n",
    "    signal_metrics[arousal_signal]['Specificity'].append(Specificity)\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    plot_roc_curve(model, X_test, y_test)\n",
    "    \n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_roc_curve.png')\n",
    "    plt.savefig(figure_path + arousal_signal.lower() + '_roc_curve.pdf')\n",
    "    \n",
    "    plt.show()\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    #                         Feature Importance\n",
    "    #####################################################################################\n",
    "    get_feature_importance(model, X_train, arousal_signal)\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    #                              PLOTTING\n",
    "    #####################################################################################\n",
    "# ??     get_all_confusion_matrices(arousal_signal, model_df, test_df, y_test, y_pred)\n",
    "# ??    get_all_confusion_matrices(arousal_signal, train_df, test_df, y_test, y_pred)\n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    #                        Classification Probabilities\n",
    "    #####################################################################################\n",
    "    y_pred_probabilities = model.predict_proba(X_test)\n",
    "    # print(y_pred_probabilities)\n",
    "    \n",
    "    test_df[\"Relaxed_Prob\"], test_df[\"Stress_Prob\"] = y_pred_probabilities[:,0], y_pred_probabilities[:,1]\n",
    "    test_df.to_csv('../../data/sim1/' + arousal_signal.lower() + '_pred_result_df.csv', sep=',')\n",
    "    \n",
    "    \n",
    "#     test_df_mean = test_df[['Prediction', 'Relaxed_Prob', 'Stress_Prob']].groupby(['Prediction']).agg({'Relaxed_Prob': 'mean', 'Stress_Prob': 'mean'})\n",
    "#     test_df_mean = test_df_mean.apply(lambda x: round(100 * x, 2))\n",
    "#     print(test_df_mean, '\\n')\n",
    "    #####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# arousal_signals = ['PP']\n",
    "arousal_signals = ['PP', 'PP_2', 'HR', 'BR']\n",
    "\n",
    "# 'PP', 'PP_2', 'HR', 'BR'\n",
    "# 'PP_HR', 'HR_BR', 'PP_BR', 'PP_HR_BR'\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "model_train_method = 'kfold' ### ['best_accurate', 'kfold', 'bootstrap']\n",
    "\n",
    "if model_train_method=='best_accurate':\n",
    "    _range=1\n",
    "    random_selection=False\n",
    "    \n",
    "elif model_train_method=='bootstrap':\n",
    "    _range=30\n",
    "    random_selection=True\n",
    "    \n",
    "elif model_train_method=='kfold':\n",
    "    subjects = np.array(model_df.Subject.unique())\n",
    "    kf = KFold(n_splits=5)\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "signal_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "for arousal_signal in arousal_signals:\n",
    "    print('----------------------------------------------------')\n",
    "    print('------------------------', arousal_signal, '------------------------')\n",
    "    print('----------------------------------------------------\\n')\n",
    "    \n",
    "    signal_metrics[arousal_signal] = {\n",
    "        'Accuracy': [],\n",
    "        'AUC': [],\n",
    "        'F1': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'Specificity': [],\n",
    "    }\n",
    "  \n",
    "    if model_train_method=='kfold':\n",
    "        for _, test_index in kf.split(subjects):\n",
    "            get_bootstrap_results(model_df, model_features, arousal_signal, model_train_method, subjects[test_index])\n",
    "            \n",
    "    else:\n",
    "        for i in range(_range):\n",
    "            # print('\\n--------------------------------------------- Iteration: ', i+1)\n",
    "            get_bootstrap_results(model_df, model_features, arousal_signal, model_train_method)\n",
    "    \n",
    "    \n",
    "# print(signal_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(signal_metrics)\n",
    "\n",
    "\n",
    "# {'PP': {'Accuracy': [0.96, 0.96, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.96, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95], 'F1': [0.95, 0.95, 0.95, 0.95, 0.95, 0.94, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.94, 0.95, 0.94, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95], 'Recall': [0.96, 0.96, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.96, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95], 'Precision': [0.96, 0.96, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.96, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.96, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]}, 'PP_2': {'Accuracy': [0.81, 0.8, 0.81, 0.8, 0.81, 0.8, 0.8, 0.81, 0.82, 0.81, 0.82, 0.81, 0.81, 0.82, 0.82, 0.81, 0.8, 0.82, 0.81, 0.81, 0.82, 0.81, 0.82, 0.81, 0.8, 0.82, 0.8, 0.82, 0.8, 0.81], 'F1': [0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.78, 0.79, 0.78, 0.79, 0.78, 0.78, 0.79, 0.79, 0.79, 0.77, 0.79, 0.78, 0.79, 0.79, 0.78, 0.79, 0.78, 0.77, 0.79, 0.78, 0.79, 0.78, 0.79], 'Recall': [0.81, 0.8, 0.81, 0.8, 0.81, 0.8, 0.8, 0.81, 0.82, 0.81, 0.82, 0.81, 0.81, 0.82, 0.82, 0.81, 0.8, 0.82, 0.81, 0.81, 0.82, 0.81, 0.82, 0.81, 0.8, 0.82, 0.8, 0.82, 0.8, 0.81], 'Precision': [0.8, 0.79, 0.81, 0.78, 0.8, 0.8, 0.79, 0.8, 0.83, 0.79, 0.82, 0.8, 0.8, 0.82, 0.83, 0.8, 0.79, 0.81, 0.8, 0.8, 0.83, 0.8, 0.83, 0.81, 0.79, 0.83, 0.79, 0.81, 0.79, 0.81]}, 'HR': {'Accuracy': [0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71], 'F1': [0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.71, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71], 'Recall': [0.73, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.73, 0.72, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71], 'Precision': [0.73, 0.72, 0.73, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71, 0.73, 0.73, 0.72, 0.72, 0.72, 0.71, 0.73, 0.72, 0.72, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.72, 0.73, 0.72, 0.71]}, 'BR': {'Accuracy': [0.79, 0.81, 0.8, 0.78, 0.78, 0.79, 0.79, 0.78, 0.79, 0.78, 0.78, 0.79, 0.79, 0.79, 0.78, 0.79, 0.79, 0.78, 0.81, 0.78, 0.79, 0.78, 0.8, 0.79, 0.8, 0.8, 0.78, 0.78, 0.79, 0.79], 'F1': [0.79, 0.81, 0.79, 0.77, 0.78, 0.78, 0.79, 0.77, 0.79, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.79, 0.79, 0.78, 0.8, 0.78, 0.78, 0.78, 0.79, 0.79, 0.8, 0.79, 0.78, 0.78, 0.79, 0.79], 'Recall': [0.79, 0.81, 0.8, 0.78, 0.78, 0.79, 0.79, 0.78, 0.79, 0.78, 0.78, 0.79, 0.79, 0.79, 0.78, 0.79, 0.79, 0.78, 0.81, 0.78, 0.79, 0.78, 0.8, 0.79, 0.8, 0.8, 0.78, 0.78, 0.79, 0.79], 'Precision': [0.8, 0.82, 0.81, 0.78, 0.79, 0.79, 0.8, 0.78, 0.8, 0.79, 0.79, 0.8, 0.8, 0.79, 0.8, 0.8, 0.8, 0.79, 0.81, 0.8, 0.79, 0.79, 0.81, 0.8, 0.81, 0.8, 0.79, 0.79, 0.8, 0.79]}, 'PP_HR_BR': {'Accuracy': [0.76, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.73, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.75, 0.76, 0.75, 0.76, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76], 'F1': [0.74, 0.74, 0.75, 0.74, 0.73, 0.74, 0.73, 0.72, 0.74, 0.74, 0.75, 0.74, 0.74, 0.75, 0.75, 0.74, 0.75, 0.74, 0.74, 0.73, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75], 'Recall': [0.76, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.73, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.75, 0.76, 0.75, 0.76, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76], 'Precision': [0.74, 0.74, 0.75, 0.74, 0.73, 0.74, 0.73, 0.72, 0.74, 0.75, 0.75, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.73, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(signal_metrics['PP']['Accuracy'])\n",
    "# print(signal_metrics['HR']['Accuracy'])\n",
    "# print(len(signal_metrics['PP']['Accuracy']))\n",
    "# print(len(signal_metrics['HR']['Accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arousal_signal in arousal_signals:\n",
    "    arousal_signal_metrics = signal_metrics[arousal_signal]\n",
    "    print(\"\\n\\n\" + arousal_signal + \" ----> \")\n",
    "    for metric in ['Accuracy', 'AUC', 'F1', 'Recall', 'Precision', 'Specificity']:\n",
    "        metric_numbers = arousal_signal_metrics[metric]\n",
    "\n",
    "        if model_train_method=='best_accurate':\n",
    "            print(metric + \": \" + get_rounded_str(metric_numbers[0], 2))\n",
    "        elif model_train_method=='bootstrap':\n",
    "            print(metric + \": \" + \n",
    "                  get_rounded_str(mean(metric_numbers), 2) + u\" \\u00B1 \" +\n",
    "                  get_rounded_str(stdev(metric_numbers), 3))\n",
    "        elif model_train_method=='kfold':\n",
    "            print(metric + \": \" + get_rounded_str(mean(metric_numbers), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# pp = pprint.PrettyPrinter(indent=1)\n",
    "\n",
    "# pp.pprint(signal_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(model_features)\n",
    "\n",
    "# plot_df = model_df.copy().rename(columns={\n",
    "#                              'Gender_Female': 'Gender', \n",
    "#                              'Effort': 'NASA_Effort',\n",
    "#                              'Frustration': 'NASA_Frustration', \n",
    "#                              'Mental_Demand': 'NASA_Mental',\n",
    "#                              'Performance': 'NASA_Performance', \n",
    "#                              'Physical_Demand': 'NASA_Physical',\n",
    "#                              'Temporal_Demand': 'NASA_Temporal', \n",
    "#                              'NASA_Total_Sum': 'NASA_Total',\n",
    "#                              'Hr_Mean': 'HR_Mean',\n",
    "#                              'Hr_SD': 'HR_SD',\n",
    "#                              'Hr_Median': 'HR_Median',\n",
    "#                              'Hr_SS': 'HR_SS',\n",
    "#                              'Br_Mean': 'BR_Mean',\n",
    "#                              'Br_SD': 'BR_SD',\n",
    "#                              'Br_Median': 'BR_Median',\n",
    "#                              'Br_SS': 'BR_SS'\n",
    "#                             })\n",
    "\n",
    "\n",
    "# # print(plot_df.columns)\n",
    "\n",
    "# plot_features = ['Age',\n",
    "#                  'Gender',\n",
    "                 \n",
    "#                  'NASA_Mental',\n",
    "#                  'NASA_Physical',\n",
    "#                  'NASA_Effort',\n",
    "#                  'NASA_Frustration',\n",
    "#                  'NASA_Temporal',\n",
    "#                  'NASA_Performance', \n",
    "#                  'NASA_Total',\n",
    "                 \n",
    "#                  'Perinasal_Mean', \n",
    "#                  'Perinasal_Median', \n",
    "#                  'Perinasal_SD',\n",
    "#                  'Perinasal_SS', \n",
    "                 \n",
    "#                  'HR_Mean', \n",
    "#                  'HR_Median', \n",
    "#                  'HR_SD', \n",
    "#                  'HR_SS', \n",
    "                 \n",
    "#                  'BR_Mean',\n",
    "#                  'BR_Median', \n",
    "#                  'BR_SD', \n",
    "#                  'BR_SS']\n",
    "\n",
    "# # print(len(model_features), len(plot_features)) ## 22, 21\n",
    "# # print(plot_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# DO NOT DELETE #\n",
    "#################\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "####----   Old Features   ----####\n",
    "##################################\n",
    "# cor_df = model_df.copy()[['Arousal_Mode',\n",
    "#                           'Perinasal_Mean', 'Perinasal_SD', 'Perinasal_Median', 'Perinasal_SS', \n",
    "#                           'Palm_Mean', 'Palm_SD', 'Palm_Median', 'Palm_SS', \n",
    "#                           'Hr_Mean', 'Hr_SD', 'Hr_Median', 'Hr_SS', \n",
    "#                           'Br_Mean', 'Br_SD', 'Br_Median', 'Br_SS',\n",
    "#                           'Drive_Label_CD', 'Drive_Label_ED', \n",
    "#                           'Drive_Label_FD', 'Drive_Label_MD'\n",
    "#                            ]]\n",
    "\n",
    "\n",
    "#############################################\n",
    "####---- only physiological Features ----####\n",
    "#############################################\n",
    "# cor_df = model_df.copy()[['Arousal_Mode', \n",
    "#                           'Perinasal_Mean', 'Perinasal_SD',\n",
    "#                           'Palm_Mean', 'Palm_SD', \n",
    "#                           'Hr_Mean', 'Hr_SD',\n",
    "#                           'Br_Mean', 'Br_SD',\n",
    "#                           'Drive_Label_CD', 'Drive_Label_ED', \n",
    "#                           'Drive_Label_FD', 'Drive_Label_MD'\n",
    "#                            ]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ###################################\n",
    "# ####----   Plot Features   ----####\n",
    "# ###################################\n",
    "# cor_df = plot_df.copy()[['Arousal_Mode'] + plot_features]\n",
    "# corr = cor_df.corr().round(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "###----   All Features   ----####\n",
    "#################################\n",
    "cor_df = model_df.copy()[['Arousal_Mode'] + model_features]\n",
    "corr = cor_df.corr().round(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "reset_plt()\n",
    "plt.figure(figsize=(40, 40))\n",
    "plt.subplot(1, 1, 1)\n",
    "\n",
    "sns_plt = sns.heatmap(corr, cmap=\"YlGnBu\", center=0, square=True, linewidths=.5, annot=True, annot_kws={\"size\": 24})\n",
    "sns_plt.collections[0].colorbar.ax.tick_params(labelsize=32)\n",
    "\n",
    "sns_plt.set_xticklabels(sns_plt.get_xticklabels(), rotation = 45, fontsize = 34, ha='right')  # 45\n",
    "sns_plt.set_yticklabels(sns_plt.get_yticklabels(), rotation = 0, fontsize = 34)\n",
    "\n",
    "\n",
    "# sns_plt.axes.set_title(\"Title\",fontsize=50)\n",
    "# sns_plt.set_xlabel(\"X Label\",fontsize=30)\n",
    "# sns_plt.set_ylabel(\"Y Label\",fontsize=20)\n",
    "# sns_plt.tick_params(labelsize=5)\n",
    "# sns_plt.plt.show()\n",
    "\n",
    "\n",
    "plt.savefig(figure_path + 'all_features_correlation_plot.png')\n",
    "plt.savefig(figure_path + 'all_features_correlation_plot.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# NON USED CODES\n",
    "##########################\n",
    "\n",
    "\n",
    "# IFrame(\"../../data/sim1/figures/pp_arousal_prediction_Cognitive_sd.pdf\", width=900, height=600)\n",
    "\n",
    "\n",
    "\n",
    "# result_df = pd.DataFrame({\n",
    "#         'actual': y_test,\n",
    "#         'prediction': y_pred,\n",
    "#         'err': y_test == y_pred\n",
    "#     }).sort_values('err', ascending = False)\n",
    "# result_df.to_csv(\"../../data/sim1/test/result_\" + arousal_signal + \".csv\", sep=',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ########################\n",
    "# PP -->\n",
    "# ########################\n",
    "# Accuracy: 0.779839208410637\n",
    "# F1: 0.7578831147346705\n",
    "# Recall: 0.779839208410637\n",
    "# Precision: 0.7987647247206715\n",
    "\n",
    "# #################################\n",
    "# PP --> Best Bootstraping for PP\n",
    "# #################################\n",
    "# Accuracy: 0.8556223970384081\n",
    "# F1: 0.8416228891876154\n",
    "# Recall: 0.8556223970384081\n",
    "# Precision: 0.8378525827410469\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# PP_2 -->\n",
    "#########################\n",
    "# Accuracy: 0.7414965986394558\n",
    "# F1: 0.7382594058202663\n",
    "# Recall: 0.7414965986394558\n",
    "# Precision: 0.7647435765692131\n",
    "\n",
    "##################################\n",
    "# PP_2 --> Best Bootstraping for PP\n",
    "##################################\n",
    "# Accuracy: 0.7431744562702453\n",
    "# F1: 0.7332696262099785\n",
    "# Recall: 0.7431744562702453\n",
    "# Precision: 0.736553172654085\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#########################\n",
    "# HR -->\n",
    "#########################\n",
    "# Accuracy: 0.6487322201607916\n",
    "# F1: 0.5998199331532664\n",
    "# Recall: 0.6487322201607916\n",
    "# Precision: 0.6352522628886266\n",
    "\n",
    "##################################\n",
    "# HR --> Best Bootstraping for PP\n",
    "##################################\n",
    "# Accuracy: 0.6598796853308654\n",
    "# F1: 0.659423920692846\n",
    "# Recall: 0.6598796853308654\n",
    "# Precision: 0.6590498579113212\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# BR -->\n",
    "#########################\n",
    "# Accuracy: 0.6951144094001237\n",
    "# F1: 0.6916477146798585\n",
    "# Recall: 0.6951144094001237\n",
    "# Precision: 0.7030998641785814\n",
    "\n",
    "##################################\n",
    "# BR --> Best Bootstraping for PP\n",
    "##################################\n",
    "# Accuracy: 0.7366959740860712\n",
    "# F1: 0.7339665422228959\n",
    "# Recall: 0.7366959740860712\n",
    "# Precision: 0.7382492602016391\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################################\n",
    "# # Ref: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "# ################################################################################################\n",
    "# X = np.array(model_df.Subject.unique())\n",
    "# kf = KFold(n_splits=5)\n",
    "# kf.get_n_splits(X)\n",
    "# print(kf)\n",
    "# KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "# #     print(\"TRAIN:\", X[train_index], \"TEST:\", X[test_index])\n",
    "#     print(\"TRAIN_IDX:\", train_index, \"TEST_IDX:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
